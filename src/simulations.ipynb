{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13d26a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:42:24.743119Z",
     "iopub.status.busy": "2025-06-11T17:42:24.742944Z",
     "iopub.status.idle": "2025-06-11T17:42:25.407302Z",
     "shell.execute_reply": "2025-06-11T17:42:25.406786Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "from scipy.stats import ks_1samp, uniform, norm, gaussian_kde\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
    "plt.style.use(\"math.mplstyle\")\n",
    "\n",
    "plt.rcParams.update({\"axes.labelsize\": 14})\n",
    "plt.rcParams.update({\"xtick.labelsize\": 14})\n",
    "plt.rcParams.update({\"ytick.labelsize\": 14})\n",
    "plt.rcParams.update({\"legend.fontsize\": 14})\n",
    "plt.rcParams.update({\"axes.titlesize\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "335f7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "xi = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee52a93",
   "metadata": {},
   "source": [
    "# Gaussian mean change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ed127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:42:25.408905Z",
     "iopub.status.busy": "2025-06-11T17:42:25.408776Z",
     "iopub.status.idle": "2025-06-11T17:42:25.444479Z",
     "shell.execute_reply": "2025-06-11T17:42:25.444189Z"
    }
   },
   "outputs": [],
   "source": [
    "timeseries = np.concatenate([np.random.normal(-1, 1, xi), np.random.normal(1, 1, n - xi)])\n",
    "\n",
    "time_indices = np.arange(1, n + 1)\n",
    "\n",
    "plt.plot(time_indices, timeseries)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347fcc1",
   "metadata": {},
   "source": [
    "## Oracle likelihood ratio score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b46420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:42:25.446270Z",
     "iopub.status.busy": "2025-06-11T17:42:25.446153Z",
     "iopub.status.idle": "2025-06-11T17:42:27.372805Z",
     "shell.execute_reply": "2025-06-11T17:42:27.372417Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_single_simulation(n, xi):\n",
    "    f_0 = norm(-1, 1)\n",
    "    f_1 = norm(1, 1)\n",
    "\n",
    "    left_scores = f_1.pdf(timeseries) / f_0.pdf(timeseries)\n",
    "    right_scores = f_0.pdf(timeseries) / f_1.pdf(timeseries)\n",
    "\n",
    "    p_values = np.zeros(n-1)\n",
    "    for t in tqdm(range(n-1)):\n",
    "        p_values_curr = np.zeros(n)\n",
    "        \n",
    "        for r in range(t+1):\n",
    "            left_segment_scores = left_scores[:r+1]\n",
    "            rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(0, 1) * np.sum(left_scores[r] ==left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "        \n",
    "        for r in range(n-1, t, -1):\n",
    "            right_segment_scores = right_scores[r:]\n",
    "            rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(0, 1) * np.sum(right_scores[r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r + 1)\n",
    "        \n",
    "        p_left = ks_1samp(p_values_curr[:t+1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t+1:], uniform.cdf, method=\"exact\")[1]\n",
    "        \n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "p_values = run_single_simulation(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffabdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:42:27.374524Z",
     "iopub.status.busy": "2025-06-11T17:42:27.374395Z",
     "iopub.status.idle": "2025-06-11T17:42:27.473730Z",
     "shell.execute_reply": "2025-06-11T17:42:27.473042Z"
    }
   },
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for Gaussian mean change (oracle score)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/oracle.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08d461",
   "metadata": {},
   "source": [
    "## Parametric learned score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametric_density(data):\n",
    "    data = np.asarray(data).reshape(-1)\n",
    "    return lambda x: norm.pdf(x, loc=np.mean(data), scale=1)\n",
    "\n",
    "\n",
    "def run_single_simulation_parametric(n, xi):\n",
    "    timeseries = np.concatenate(\n",
    "        [np.random.normal(-1, 1, xi), np.random.normal(1, 1, n - xi)]\n",
    "    )\n",
    "\n",
    "    p_values = np.zeros(n - 1)\n",
    "\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        left_scores = np.zeros(n)\n",
    "        right_scores = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            data_f0 = timeseries[: r + 1]\n",
    "            kde_f0 = compute_kde(data_f0)\n",
    "            f0_score = kde_f0(timeseries[r])\n",
    "\n",
    "            if t + 1 >= n:\n",
    "                left_scores[r] = 1.0\n",
    "                continue\n",
    "\n",
    "            data_f1 = timeseries[t + 1 :]\n",
    "            if len(data_f1) == 0:\n",
    "                left_scores[r] = 1.0\n",
    "                continue\n",
    "\n",
    "            kde_f1 = compute_kde(data_f1)\n",
    "            f1_score = kde_f1(timeseries[r])\n",
    "\n",
    "            left_scores[r] = f1_score / (\n",
    "                f0_score + 1e-10\n",
    "            )\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            data_f1 = timeseries[r:]\n",
    "            kde_f1 = compute_kde(data_f1)\n",
    "            f1_score = kde_f1(timeseries[r])\n",
    "\n",
    "            data_f0 = timeseries[: t + 1]\n",
    "            kde_f0 = compute_kde(data_f0)\n",
    "            f0_score = kde_f0(timeseries[r])\n",
    "\n",
    "            right_scores[r] = f0_score / (f1_score + 1e-10)\n",
    "\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            left_segment_scores = left_scores[: r + 1]\n",
    "            rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            right_segment_scores = right_scores[r:]\n",
    "            rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(right_scores[r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        try:\n",
    "            if t > 0:\n",
    "                p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[\n",
    "                    1\n",
    "                ]\n",
    "            else:\n",
    "                p_left = 1.0\n",
    "\n",
    "            if t + 1 < n:\n",
    "                p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[\n",
    "                    1\n",
    "                ]\n",
    "            else:\n",
    "                p_right = 1.0\n",
    "        except:\n",
    "            p_left = 1.0\n",
    "            p_right = 1.0\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "p_values = run_single_simulation_parametric(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ada403",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for Gaussian mean change (parametric learned score)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/parametric.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115fe7e",
   "metadata": {},
   "source": [
    "## Kernel density estimator (KDE) learned score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db173ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kde(data):\n",
    "    data = np.asarray(data).reshape(-1)\n",
    "    if len(data) <= 1:\n",
    "        mean = data[0] if len(data) == 1 else 0\n",
    "        return lambda x: norm.pdf(x, loc=mean, scale=0.1)\n",
    "    return gaussian_kde(data)\n",
    "\n",
    "\n",
    "def run_single_simulation_kde(n, xi):\n",
    "    timeseries = np.concatenate(\n",
    "        [np.random.normal(-1, 1, xi), np.random.normal(1, 1, n - xi)]\n",
    "    )\n",
    "\n",
    "    p_values = np.zeros(n - 1)\n",
    "\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        left_scores = np.zeros(n)\n",
    "        right_scores = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            data_f0 = timeseries[: r + 1]\n",
    "            kde_f0 = compute_kde(data_f0)\n",
    "            f0_score = kde_f0(timeseries[r])\n",
    "\n",
    "            if t + 1 >= n:\n",
    "                left_scores[r] = 1.0\n",
    "                continue\n",
    "\n",
    "            data_f1 = timeseries[t + 1 :]\n",
    "            if len(data_f1) == 0:\n",
    "                left_scores[r] = 1.0\n",
    "                continue\n",
    "\n",
    "            kde_f1 = compute_kde(data_f1)\n",
    "            f1_score = kde_f1(timeseries[r])\n",
    "\n",
    "            left_scores[r] = f1_score / (\n",
    "                f0_score + 1e-10\n",
    "            )\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            data_f1 = timeseries[r:]\n",
    "            kde_f1 = compute_kde(data_f1)\n",
    "            f1_score = kde_f1(timeseries[r])\n",
    "\n",
    "            data_f0 = timeseries[: t + 1]\n",
    "            kde_f0 = compute_kde(data_f0)\n",
    "            f0_score = kde_f0(timeseries[r])\n",
    "\n",
    "            right_scores[r] = f0_score / (f1_score + 1e-10)\n",
    "\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            left_segment_scores = left_scores[: r + 1]\n",
    "            rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            right_segment_scores = right_scores[r:]\n",
    "            rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(right_scores[r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        try:\n",
    "            if t > 0:\n",
    "                p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[\n",
    "                    1\n",
    "                ]\n",
    "            else:\n",
    "                p_left = 1.0\n",
    "\n",
    "            if t + 1 < n:\n",
    "                p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[\n",
    "                    1\n",
    "                ]\n",
    "            else:\n",
    "                p_right = 1.0\n",
    "        except:\n",
    "            p_left = 1.0\n",
    "            p_right = 1.0\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "p_values = run_single_simulation_kde(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d831e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for Gaussian mean change (KDE learned score)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/kde.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76883e3c",
   "metadata": {},
   "source": [
    "## Coverage and width simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fbc2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_simulation(n, xi):\n",
    "    timeseries = np.concatenate([np.random.normal(-1, 1, xi), np.random.normal(1, 1, n - xi)])\n",
    "    \n",
    "    f_0 = norm(-1, 1)\n",
    "    f_1 = norm(1, 1)\n",
    "    \n",
    "    left_scores = f_1.pdf(timeseries) / f_0.pdf(timeseries)\n",
    "    right_scores = f_0.pdf(timeseries) / f_1.pdf(timeseries)\n",
    "    \n",
    "    p_values = np.zeros(n-1)\n",
    "    for t in range(n-1):\n",
    "        p_values_curr = np.zeros(n)\n",
    "        \n",
    "        for r in range(t+1):\n",
    "            left_segment_scores = left_scores[:r+1]\n",
    "            rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(0, 1) * np.sum(left_scores[r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "        \n",
    "        for r in range(n-1, t, -1):\n",
    "            right_segment_scores = right_scores[r:]\n",
    "            rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(0, 1) * np.sum(right_scores[r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r + 1)\n",
    "        \n",
    "        p_left = ks_1samp(p_values_curr[:t+1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t+1:], uniform.cdf, method=\"exact\")[1]\n",
    "        \n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "    \n",
    "    return p_values\n",
    "\n",
    "def run_simulation_study(n_simulations=1000, n=500, xi=200):\n",
    "    all_p_values = np.zeros((n_simulations, n-1))\n",
    "    \n",
    "    coverages_95 = []\n",
    "    coverages_50 = []\n",
    "    widths_95 = []\n",
    "    widths_50 = []\n",
    "    detected_cps = []\n",
    "    \n",
    "    pbar = tqdm(range(n_simulations))\n",
    "    \n",
    "    for i in pbar:\n",
    "        p_values = run_single_simulation(n, xi)\n",
    "        all_p_values[i] = p_values\n",
    "        \n",
    "        coverage_95 = p_values[xi-1] > 0.05\n",
    "        coverage_50 = p_values[xi-1] > 0.50\n",
    "        width_95 = np.sum(p_values > 0.05)\n",
    "        width_50 = np.sum(p_values > 0.50)\n",
    "        detected_cp = np.argmax(p_values) + 1\n",
    "        \n",
    "        coverages_95.append(coverage_95)\n",
    "        coverages_50.append(coverage_50)\n",
    "        widths_95.append(width_95)\n",
    "        widths_50.append(width_50)\n",
    "        detected_cps.append(detected_cp)\n",
    "        \n",
    "        if i > 0:\n",
    "            running_cov_95 = np.mean(coverages_95)\n",
    "            running_cov_50 = np.mean(coverages_50)\n",
    "            running_width_95 = np.mean(widths_95)\n",
    "            running_error = np.mean([abs(cp - xi) for cp in detected_cps])\n",
    "            \n",
    "            pbar.set_description(f\"Cov95:{running_cov_95:.3f} Cov50:{running_cov_50:.3f} W95:{running_width_95:.1f} Err:{running_error:.1f}\")\n",
    "    \n",
    "    return all_p_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_p_values = run_simulation_study(n_simulations=1000, n=500, xi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1906929",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 200\n",
    "n_simulations, n_minus_1 = all_p_values.shape\n",
    "\n",
    "coverage_95 = all_p_values[:, xi-1] > 0.05\n",
    "coverage_50 = all_p_values[:, xi-1] > 0.50\n",
    "\n",
    "widths_95 = np.sum(all_p_values > 0.05, axis=1)\n",
    "widths_50 = np.sum(all_p_values > 0.50, axis=1)\n",
    "\n",
    "detected_cps = np.argmax(all_p_values, axis=1) + 1\n",
    "detection_errors = np.abs(detected_cps - xi)\n",
    "\n",
    "print(f\"95% Coverage: {np.mean(coverage_95):.3f}\")\n",
    "print(f\"50% Coverage: {np.mean(coverage_50):.3f}\")\n",
    "print(f\"Average Width (95%): {np.mean(widths_95):.1f}\")\n",
    "print(f\"Average Width (50%): {np.mean(widths_50):.1f}\")\n",
    "print(f\"Average Detection Error: {np.mean(detection_errors):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77582ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(widths_95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(detection_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(detected_cps)\n",
    "plt.axvline(x=200, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6fe4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_p_values.npy', all_p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b650cf3",
   "metadata": {},
   "source": [
    "# MNIST digit change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07b9ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_trained_model(device=\"cpu\"):\n",
    "    class MNISTModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MNISTModel, self).__init__()\n",
    "            self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = torch.nn.Dropout(0.25)\n",
    "            self.dropout2 = torch.nn.Dropout(0.5)\n",
    "            self.fc1 = torch.nn.Linear(9216, 128)\n",
    "            self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = torch.nn.functional.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    model = MNISTModel().to(device)\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "    train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Training MNIST model...\")\n",
    "    model.train()\n",
    "    for epoch in range(1):\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\n",
    "                    f\"Epoch: {epoch} [{batch_idx*len(data)}/{len(train_loader.dataset)} \"\n",
    "                    f\"({100. * batch_idx / len(train_loader):.0f}%)]\\\\tLoss: {loss.item():.6f}\"\n",
    "                )\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_digit(model, image, device=\"cpu\"):\n",
    "    image = image.reshape(1, 1, 28, 28)\n",
    "    image_tensor = torch.tensor(image, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = torch.softmax(model(image_tensor), dim=1).cpu()\n",
    "        predicted = outputs.argmax(dim=1).item()\n",
    "    return (predicted, outputs)\n",
    "\n",
    "\n",
    "def generate_mnist_dataset(length, changepoint, digit1=3, digit2=7):\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    data = mnist_data.data.numpy()\n",
    "    targets = mnist_data.targets.numpy()\n",
    "\n",
    "    images_digit1 = data[targets == digit1]\n",
    "    images_digit2 = data[targets == digit2]\n",
    "    np.random.shuffle(images_digit1)\n",
    "    np.random.shuffle(images_digit2)\n",
    "\n",
    "    n1 = changepoint + 1\n",
    "    n2 = length - n1\n",
    "    if n1 > len(images_digit1) or n2 > len(images_digit2):\n",
    "        raise ValueError(\"Insufficient images for the specified digits and length.\")\n",
    "\n",
    "    data1 = images_digit1[:n1]\n",
    "    data2 = images_digit2[:n2]\n",
    "    x = np.concatenate([data1, data2], axis=0)\n",
    "\n",
    "    x = x.reshape(length, -1).astype(np.float32) / 255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b70fc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sequential_scores(x, model, device=\"cpu\"):\n",
    "    length = len(x)\n",
    "\n",
    "    print(\"Getting model predictions...\")\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for i in tqdm(range(length)):\n",
    "        pred, prob = predict_digit(model, x[i], device)\n",
    "        predictions.append(pred)\n",
    "        probabilities.append(prob.squeeze())\n",
    "\n",
    "    probabilities = torch.stack(probabilities)\n",
    "\n",
    "    left_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing left scores for each t\"):\n",
    "        reference = max(predictions[t+1:], key=predictions[t+1:].count)\n",
    "        for r in range(t + 1):\n",
    "            seen_digits = {}\n",
    "            for i in range(r + 1):\n",
    "                digit = predictions[i]\n",
    "                seen_digits[digit] = seen_digits.get(digit, 0) + 1\n",
    "\n",
    "            baseline_digit = max(seen_digits, key=seen_digits.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_digit]\n",
    "            left_scores[t, r] = prob_baseline / (probabilities[r, reference] + 1e-10)\n",
    "\n",
    "    right_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing right scores for each t\"):\n",
    "        reference = max(predictions[:t+1], key=predictions[:t+1].count)\n",
    "        for r in range(t + 1, length):\n",
    "            seen_digits = {}\n",
    "            for i in range(r, length):\n",
    "                digit = predictions[i]\n",
    "                seen_digits[digit] = seen_digits.get(digit, 0) + 1\n",
    "\n",
    "            baseline_digit = max(seen_digits, key=seen_digits.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_digit]\n",
    "            right_scores[t, r] = prob_baseline / (probabilities[r, reference] + 1e-10)\n",
    "\n",
    "    return left_scores, right_scores, predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601689df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mnist_simulation(n, xi):\n",
    "    x = generate_mnist_dataset(n, xi)\n",
    "    left_scores, right_scores, predictions, probabilities = compute_sequential_scores(\n",
    "        x, model\n",
    "    )\n",
    "    p_values = np.zeros(n - 1)\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t+1):\n",
    "            left_segment_scores = left_scores[t, : r + 1]\n",
    "            rank = np.sum(left_scores[t, r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[t, r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(n - 1, t, -1):\n",
    "            right_segment_scores = right_scores[t, r:]\n",
    "            rank = np.sum(right_scores[t, r] < right_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(right_scores[t, r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "p_values = run_mnist_simulation(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2147a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(\n",
    "    0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\"\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for MNIST digit change (digit classifier)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mnist-pvalues.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6862e3c",
   "metadata": {},
   "source": [
    "# SST-2 sentiment change (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50e2545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_sentiment_model(device=\"cpu\"):\n",
    "    model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def generate_sentiment_dataset(length, changepoint, dataset_name=\"sst2\"):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    train_data = dataset[\"train\"]\n",
    "    positive_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 1]\n",
    "    negative_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 0]\n",
    "\n",
    "    random.shuffle(positive_texts)\n",
    "    random.shuffle(negative_texts)\n",
    "\n",
    "    n1 = changepoint + 1\n",
    "    n2 = length - n1\n",
    "\n",
    "    if n1 > len(positive_texts) or n2 > len(negative_texts):\n",
    "        raise ValueError(\"Insufficient texts for the specified length and changepoint.\")\n",
    "\n",
    "    texts_before = positive_texts[:n1]\n",
    "    texts_after = negative_texts[:n2]\n",
    "\n",
    "    texts = texts_before + texts_after\n",
    "    true_labels = [1] * n1 + [0] * n2\n",
    "\n",
    "    return texts, true_labels\n",
    "\n",
    "\n",
    "def generate_mixed_sentiment_dataset(length, changepoint, dataset_name=\"sst2\"):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    train_data = dataset[\"train\"]\n",
    "    positive_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 1]\n",
    "    negative_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 0]\n",
    "\n",
    "    random.shuffle(positive_texts)\n",
    "    random.shuffle(negative_texts)\n",
    "\n",
    "    n_pre = changepoint + 1\n",
    "    n_post = length - n_pre\n",
    "\n",
    "    n_pos_pre = int(n_pre * 0.6)\n",
    "    n_neg_pre = n_pre - n_pos_pre\n",
    "\n",
    "    n_pos_post = int(n_post * 0.4)\n",
    "    n_neg_post = n_post - n_pos_post\n",
    "\n",
    "    if n_pos_pre + n_pos_post > len(positive_texts) or n_neg_pre + n_neg_post > len(\n",
    "        negative_texts\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Insufficient texts for the specified distribution and length.\"\n",
    "        )\n",
    "\n",
    "    pre_pos_texts = positive_texts[:n_pos_pre]\n",
    "    pre_neg_texts = negative_texts[:n_neg_pre]\n",
    "    pre_texts = pre_pos_texts + pre_neg_texts\n",
    "    pre_labels = [1] * n_pos_pre + [0] * n_neg_pre\n",
    "\n",
    "    pre_combined = list(zip(pre_texts, pre_labels))\n",
    "    random.shuffle(pre_combined)\n",
    "    pre_texts, pre_labels = zip(*pre_combined)\n",
    "\n",
    "    post_pos_texts = positive_texts[n_pos_pre : n_pos_pre + n_pos_post]\n",
    "    post_neg_texts = negative_texts[n_neg_pre : n_neg_pre + n_neg_post]\n",
    "    post_texts = post_pos_texts + post_neg_texts\n",
    "    post_labels = [1] * n_pos_post + [0] * n_neg_post\n",
    "\n",
    "    post_combined = list(zip(post_texts, post_labels))\n",
    "    random.shuffle(post_combined)\n",
    "    post_texts, post_labels = zip(*post_combined)\n",
    "\n",
    "    texts = list(pre_texts) + list(post_texts)\n",
    "    true_labels = list(pre_labels) + list(post_labels)\n",
    "\n",
    "    return texts, true_labels\n",
    "\n",
    "\n",
    "def predict_sentiment(model, tokenizer, text, device=\"cpu\"):\n",
    "    inputs = tokenizer(\n",
    "        text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).cpu()\n",
    "        predicted = probs.argmax(dim=1).item()\n",
    "\n",
    "    return (predicted, probs.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc830d8c",
   "metadata": {},
   "source": [
    "## Plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af035cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "changepoint = 400\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, tokenizer = get_pretrained_sentiment_model(device)\n",
    "\n",
    "print(\"Generating sentiment dataset...\")\n",
    "texts, true_labels = generate_sentiment_dataset(length, changepoint)\n",
    "\n",
    "print(\"Getting predictions...\")\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "for i, text in enumerate(tqdm(texts)):\n",
    "    pred, prob = predict_sentiment(model, tokenizer, text, device)\n",
    "    predictions.append(pred)\n",
    "    probabilities.append(prob)\n",
    "\n",
    "probabilities = torch.stack(probabilities)\n",
    "\n",
    "print(\"\\nExamples before changepoint (positive):\")\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(0, changepoint)\n",
    "    print(f'Text {i+1}: \"{texts[idx]}\"')\n",
    "    print(\n",
    "        f\"True label: Positive, Predicted: {'Positive' if predictions[idx] == 1 else 'Negative'}\"\n",
    "    )\n",
    "    print(f\"Confidence: {probabilities[idx][predictions[idx]]:.4f}\\n\")\n",
    "\n",
    "print(\"\\nExamples after changepoint (negative):\")\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(changepoint + 1, length)\n",
    "    print(f'Text {i+1}: \"{texts[idx]}\"')\n",
    "    print(\n",
    "        f\"True label: Negative, Predicted: {'Positive' if predictions[idx] == 1 else 'Negative'}\"\n",
    "    )\n",
    "    print(f\"Confidence: {probabilities[idx][predictions[idx]]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "43494506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sequential_sentiment_scores(texts, model, tokenizer, device=\"cpu\"):\n",
    "    length = len(texts)\n",
    "\n",
    "    print(\"Getting model predictions...\")\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for i, text in enumerate(tqdm(texts)):\n",
    "        pred, prob = predict_sentiment(model, tokenizer, text, device)\n",
    "        predictions.append(pred)\n",
    "        probabilities.append(prob)\n",
    "\n",
    "    probabilities = torch.stack(probabilities)\n",
    "\n",
    "    left_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing left scores for each t\"):\n",
    "        for r in range(t + 1):\n",
    "            seen_sentiments = {0: 0, 1: 0}\n",
    "            for i in range(r + 1):\n",
    "                sentiment = predictions[i]\n",
    "                seen_sentiments[sentiment] += 1\n",
    "\n",
    "            baseline_sentiment = max(seen_sentiments, key=seen_sentiments.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_sentiment]\n",
    "            left_scores[t, r] = prob_baseline / (1 - prob_baseline + 1e-10)\n",
    "\n",
    "    right_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing right scores for each t\"):\n",
    "        for r in range(t + 1, length):\n",
    "            seen_sentiments = {0: 0, 1: 0}\n",
    "            for i in range(r, length):\n",
    "                sentiment = predictions[i]\n",
    "                seen_sentiments[sentiment] += 1\n",
    "\n",
    "            baseline_sentiment = max(seen_sentiments, key=seen_sentiments.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_sentiment]\n",
    "            right_scores[t, r] = prob_baseline / (1 - prob_baseline + 1e-10)\n",
    "\n",
    "    return left_scores, right_scores, predictions, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4e30b",
   "metadata": {},
   "source": [
    "## Full sentiment change (pos. to neg.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sentiment_simulation(n, xi):\n",
    "    x, y = generate_sentiment_dataset(n, xi)\n",
    "    left_scores, right_scores, predictions, probabilities = compute_sequential_sentiment_scores(x, model, tokenizer, device)\n",
    "\n",
    "    p_values = np.zeros(n - 1)\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            left_segment_scores = left_scores[t, : r + 1]\n",
    "            rank = np.sum(left_scores[t, r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[t, r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            right_segment_scores = right_scores[t, r:]\n",
    "            rank = np.sum(\n",
    "                right_scores[t, r] < right_segment_scores\n",
    "            ) + np.random.uniform(0, 1) * np.sum(\n",
    "                right_scores[t, r] == right_segment_scores\n",
    "            )\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "p_values = run_sentiment_simulation(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eefefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for SST-2 sentiment change\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/sentiment-pvalues.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790001f",
   "metadata": {},
   "source": [
    "## Mixed sentiment change (60% pos. to 60% neg.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c276ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mixed_sentiment_simulation(n, xi):\n",
    "    x, y = generate_mixed_sentiment_dataset(n, xi)\n",
    "    left_scores, right_scores, predictions, probabilities = (\n",
    "        compute_sequential_sentiment_scores(x, model, tokenizer, device)\n",
    "    )\n",
    "\n",
    "    p_values = np.zeros(n - 1)\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            left_segment_scores = left_scores[t, : r + 1]\n",
    "            rank = np.sum(left_scores[t, r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[t, r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            right_segment_scores = right_scores[t, r:]\n",
    "            rank = np.sum(\n",
    "                right_scores[t, r] < right_segment_scores\n",
    "            ) + np.random.uniform(0, 1) * np.sum(\n",
    "                right_scores[t, r] == right_segment_scores\n",
    "            )\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "p_values = run_mixed_sentiment_simulation(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for SST-2 mixed sentiment change\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/sentiment-pvalues-mixed.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

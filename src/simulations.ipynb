{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d26a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:42:24.743119Z",
     "iopub.status.busy": "2025-06-11T17:42:24.742944Z",
     "iopub.status.idle": "2025-06-11T17:42:25.407302Z",
     "shell.execute_reply": "2025-06-11T17:42:25.406786Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "from scipy.stats import ks_1samp, uniform, norm, gaussian_kde\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
    "plt.style.use(\"math.mplstyle\")\n",
    "\n",
    "plt.rcParams.update({\"axes.labelsize\": 14})\n",
    "plt.rcParams.update({\"xtick.labelsize\": 14})\n",
    "plt.rcParams.update({\"ytick.labelsize\": 14})\n",
    "plt.rcParams.update({\"legend.fontsize\": 14})\n",
    "plt.rcParams.update({\"axes.titlesize\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "xi = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee52a93",
   "metadata": {},
   "source": [
    "# Gaussian mean change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ed127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:42:25.408905Z",
     "iopub.status.busy": "2025-06-11T17:42:25.408776Z",
     "iopub.status.idle": "2025-06-11T17:42:25.444479Z",
     "shell.execute_reply": "2025-06-11T17:42:25.444189Z"
    }
   },
   "outputs": [],
   "source": [
    "timeseries = np.concatenate([np.random.normal(-1, 1, xi), np.random.normal(1, 1, n - xi)])\n",
    "\n",
    "time_indices = np.arange(1, n + 1)\n",
    "\n",
    "plt.plot(time_indices, timeseries)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347fcc1",
   "metadata": {},
   "source": [
    "## Oracle likelihood ratio score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b46420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:42:25.446270Z",
     "iopub.status.busy": "2025-06-11T17:42:25.446153Z",
     "iopub.status.idle": "2025-06-11T17:42:27.372805Z",
     "shell.execute_reply": "2025-06-11T17:42:27.372417Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_p_value_for_t(t, n, timeseries, left_scores, right_scores):\n",
    "    p_values_curr = np.zeros(n)\n",
    "    \n",
    "    for r in range(t+1):\n",
    "        left_segment_scores = left_scores[:r+1]\n",
    "        rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(0, 1) * np.sum(left_scores[r] == left_segment_scores)\n",
    "        p_values_curr[r] = rank / (r + 1)\n",
    "    \n",
    "    for r in range(n-1, t, -1):\n",
    "        right_segment_scores = right_scores[r:]\n",
    "        rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(0, 1) * np.sum(right_scores[r] == right_segment_scores)\n",
    "        p_values_curr[r] = rank / (n - r + 1)\n",
    "    \n",
    "    p_left = ks_1samp(p_values_curr[:t+1], uniform.cdf, method=\"exact\")[1]\n",
    "    p_right = ks_1samp(p_values_curr[t+1:], uniform.cdf, method=\"exact\")[1]\n",
    "    \n",
    "    return 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "def run_single_simulation(n, xi):\n",
    "    f_0 = norm(-1, 1)\n",
    "    f_1 = norm(1, 1)\n",
    "\n",
    "    left_scores = f_1.pdf(timeseries) / f_0.pdf(timeseries)\n",
    "    right_scores = f_0.pdf(timeseries) / f_1.pdf(timeseries)\n",
    "\n",
    "    p_values = Parallel(n_jobs=-1, verbose=1)(\n",
    "        delayed(compute_p_value_for_t)(t, n, timeseries, left_scores, right_scores) \n",
    "        for t in range(n-1)\n",
    "    )\n",
    "    \n",
    "    return np.array(p_values)\n",
    "\n",
    "p_values = run_single_simulation(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffabdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T17:42:27.374524Z",
     "iopub.status.busy": "2025-06-11T17:42:27.374395Z",
     "iopub.status.idle": "2025-06-11T17:42:27.473730Z",
     "shell.execute_reply": "2025-06-11T17:42:27.473042Z"
    }
   },
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for Gaussian mean change (oracle score)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/oracle.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08d461",
   "metadata": {},
   "source": [
    "## Parametric learned score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametric_density(data):\n",
    "    data = np.asarray(data).reshape(-1)\n",
    "    return lambda x: norm.pdf(x, loc=np.mean(data), scale=1)\n",
    "\n",
    "def _parametric_p_value_for_t(t, timeseries):\n",
    "    n = len(timeseries)\n",
    "    left_scores = np.zeros(n)\n",
    "    right_scores = np.zeros(n)\n",
    "    for r in range(t + 1):\n",
    "        data_f0 = timeseries[: r + 1]\n",
    "        kde_f0 = parametric_density(data_f0)\n",
    "        if t + 1 >= n:\n",
    "            left_scores[r] = 1.0\n",
    "            continue\n",
    "        data_f1 = timeseries[t + 1 :]\n",
    "        if len(data_f1) == 0:\n",
    "            left_scores[r] = 1.0\n",
    "            continue\n",
    "        kde_f1 = parametric_density(data_f1)\n",
    "        for i in range(r + 1):\n",
    "            left_scores[i] = kde_f1(timeseries[i]) / (kde_f0(timeseries[i]) + 1e-10)\n",
    "    for r in range(t + 1, n):\n",
    "        data_f1 = timeseries[r:]\n",
    "        kde_f1 = parametric_density(data_f1)\n",
    "        data_f0 = timeseries[: t + 1]\n",
    "        kde_f0 = parametric_density(data_f0)\n",
    "        for i in range(r, n):\n",
    "            right_scores[i] = kde_f0(timeseries[i]) / (kde_f1(timeseries[i]) + 1e-10)\n",
    "    p_values_curr = np.zeros(n)\n",
    "    for r in range(t + 1):\n",
    "        left_segment_scores = left_scores[: r + 1]\n",
    "        rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(0, 1) * np.sum(left_scores[r] == left_segment_scores)\n",
    "        p_values_curr[r] = rank / (r + 1)\n",
    "    for r in range(t + 1, n):\n",
    "        right_segment_scores = right_scores[r:]\n",
    "        rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(0, 1) * np.sum(right_scores[r] == right_segment_scores)\n",
    "        p_values_curr[r] = rank / (n - r)\n",
    "    try:\n",
    "        if t > 0:\n",
    "            p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        else:\n",
    "            p_left = 1.0\n",
    "        if t + 1 < n:\n",
    "            p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "        else:\n",
    "            p_right = 1.0\n",
    "    except:\n",
    "        p_left = 1.0\n",
    "        p_right = 1.0\n",
    "    return 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "def run_single_simulation_parametric(n, xi):\n",
    "    timeseries = np.concatenate([np.random.normal(-1, 1, xi), np.random.normal(1, 1, n - xi)])\n",
    "    p_values = Parallel(n_jobs=-1, verbose=1)(delayed(_parametric_p_value_for_t)(t, timeseries) for t in range(n - 1))\n",
    "    return np.array(p_values)\n",
    "\n",
    "p_values = run_single_simulation_parametric(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ada403",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for Gaussian mean change (parametric learned score)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/parametric.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115fe7e",
   "metadata": {},
   "source": [
    "## Kernel density estimator (KDE) learned score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db173ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kde(data):\n",
    "    data = np.asarray(data).reshape(-1)\n",
    "    if len(data) <= 1:\n",
    "        mean = data[0] if len(data) == 1 else 0\n",
    "        return lambda x: norm.pdf(x, loc=mean, scale=0.1)\n",
    "    return gaussian_kde(data)\n",
    "\n",
    "def _kde_p_value_for_t(t, timeseries):\n",
    "    n = len(timeseries)\n",
    "    left_scores = np.zeros(n)\n",
    "    right_scores = np.zeros(n)\n",
    "\n",
    "    for r in range(t + 1):\n",
    "        data_f0 = timeseries[: r + 1]\n",
    "        kde_f0 = compute_kde(data_f0)\n",
    "\n",
    "        if t + 1 >= n:\n",
    "            left_scores[r] = 1.0\n",
    "            continue\n",
    "\n",
    "        data_f1 = timeseries[t + 1 :]\n",
    "        if len(data_f1) == 0:\n",
    "            left_scores[r] = 1.0\n",
    "            continue\n",
    "\n",
    "        kde_f1 = compute_kde(data_f1)\n",
    "        left_scores[: r + 1] = kde_f1(timeseries[: r + 1]) / (\n",
    "            kde_f0(timeseries[: r + 1]) + 1e-10\n",
    "        )\n",
    "\n",
    "    for r in range(t + 1, n):\n",
    "        data_f1 = timeseries[r:]\n",
    "        kde_f1 = compute_kde(data_f1)\n",
    "        data_f0 = timeseries[: t + 1]\n",
    "        kde_f0 = compute_kde(data_f0)\n",
    "        right_scores[r:] = kde_f0(timeseries[r:]) / (\n",
    "            kde_f1(timeseries[r:]) + 1e-10\n",
    "        )\n",
    "\n",
    "    p_values_curr = np.zeros(n)\n",
    "\n",
    "    for r in range(t + 1):\n",
    "        left_segment_scores = left_scores[: r + 1]\n",
    "        rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(0, 1) * np.sum(\n",
    "            left_scores[r] == left_segment_scores\n",
    "        )\n",
    "        p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "    for r in range(t + 1, n):\n",
    "        right_segment_scores = right_scores[r:]\n",
    "        rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(0, 1) * np.sum(\n",
    "            right_scores[r] == right_segment_scores\n",
    "        )\n",
    "        p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "    try:\n",
    "        if t > 0:\n",
    "            p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        else:\n",
    "            p_left = 1.0\n",
    "        if t + 1 < n:\n",
    "            p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "        else:\n",
    "            p_right = 1.0\n",
    "    except Exception:\n",
    "        p_left = 1.0\n",
    "        p_right = 1.0\n",
    "\n",
    "    return 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "def run_single_simulation_kde(n, xi, n_jobs=-1, verbose=1):\n",
    "    timeseries = np.concatenate(\n",
    "        [np.random.normal(-1, 1, xi), np.random.normal(1, 1, n - xi)]\n",
    "    )\n",
    "    p_values = Parallel(n_jobs=n_jobs, verbose=verbose)(\n",
    "        delayed(_kde_p_value_for_t)(t, timeseries) for t in range(n - 1)\n",
    "    )\n",
    "    return np.array(p_values)\n",
    "\n",
    "p_values = run_single_simulation_kde(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d831e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for Gaussian mean change (KDE learned score)\")\n",
    "plt.legend()\n",
    "# plt.savefig(\"images/kde.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76883e3c",
   "metadata": {},
   "source": [
    "## Coverage and width simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_simulation(n, xi):\n",
    "    timeseries = np.concatenate([np.random.normal(-1, 1, xi), np.random.normal(1, 1, n - xi)])\n",
    "    \n",
    "    f_0 = norm(-1, 1)\n",
    "    f_1 = norm(1, 1)\n",
    "    \n",
    "    left_scores = f_1.pdf(timeseries) / f_0.pdf(timeseries)\n",
    "    right_scores = f_0.pdf(timeseries) / f_1.pdf(timeseries)\n",
    "    \n",
    "    p_values = np.zeros(n-1)\n",
    "    for t in range(n-1):\n",
    "        p_values_curr = np.zeros(n)\n",
    "        \n",
    "        for r in range(t+1):\n",
    "            left_segment_scores = left_scores[:r+1]\n",
    "            rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(0, 1) * np.sum(left_scores[r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "        \n",
    "        for r in range(n-1, t, -1):\n",
    "            right_segment_scores = right_scores[r:]\n",
    "            rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(0, 1) * np.sum(right_scores[r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r + 1)\n",
    "        \n",
    "        p_left = ks_1samp(p_values_curr[:t+1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t+1:], uniform.cdf, method=\"exact\")[1]\n",
    "        \n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "    \n",
    "    return p_values\n",
    "\n",
    "def run_simulation_study(n_simulations=1000, n=500, xi=200):\n",
    "    all_p_values = np.zeros((n_simulations, n-1))\n",
    "    \n",
    "    coverages_95 = []\n",
    "    coverages_50 = []\n",
    "    widths_95 = []\n",
    "    widths_50 = []\n",
    "    detected_cps = []\n",
    "    \n",
    "    pbar = tqdm(range(n_simulations))\n",
    "    \n",
    "    for i in pbar:\n",
    "        p_values = run_single_simulation(n, xi)\n",
    "        all_p_values[i] = p_values\n",
    "        \n",
    "        coverage_95 = p_values[xi-1] > 0.05\n",
    "        coverage_50 = p_values[xi-1] > 0.50\n",
    "        width_95 = np.sum(p_values > 0.05)\n",
    "        width_50 = np.sum(p_values > 0.50)\n",
    "        detected_cp = np.argmax(p_values) + 1\n",
    "        \n",
    "        coverages_95.append(coverage_95)\n",
    "        coverages_50.append(coverage_50)\n",
    "        widths_95.append(width_95)\n",
    "        widths_50.append(width_50)\n",
    "        detected_cps.append(detected_cp)\n",
    "        \n",
    "        if i > 0:\n",
    "            running_cov_95 = np.mean(coverages_95)\n",
    "            running_cov_50 = np.mean(coverages_50)\n",
    "            running_width_95 = np.mean(widths_95)\n",
    "            running_error = np.mean([abs(cp - xi) for cp in detected_cps])\n",
    "            \n",
    "            pbar.set_description(f\"Cov95:{running_cov_95:.3f} Cov50:{running_cov_50:.3f} W95:{running_width_95:.1f} Err:{running_error:.1f}\")\n",
    "    \n",
    "    return all_p_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_p_values = run_simulation_study(n_simulations=1000, n=500, xi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1906929",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 200\n",
    "n_simulations, n_minus_1 = all_p_values.shape\n",
    "\n",
    "coverage_95 = all_p_values[:, xi-1] > 0.05\n",
    "coverage_50 = all_p_values[:, xi-1] > 0.50\n",
    "\n",
    "widths_95 = np.sum(all_p_values > 0.05, axis=1)\n",
    "widths_50 = np.sum(all_p_values > 0.50, axis=1)\n",
    "\n",
    "detected_cps = np.argmax(all_p_values, axis=1) + 1\n",
    "detection_errors = np.abs(detected_cps - xi)\n",
    "\n",
    "print(f\"95% Coverage: {np.mean(coverage_95):.3f}\")\n",
    "print(f\"50% Coverage: {np.mean(coverage_50):.3f}\")\n",
    "print(f\"Average Width (95%): {np.mean(widths_95):.1f}\")\n",
    "print(f\"Average Width (50%): {np.mean(widths_50):.1f}\")\n",
    "print(f\"Average Detection Error: {np.mean(detection_errors):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77582ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(widths_95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(detection_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(detected_cps)\n",
    "plt.axvline(x=200, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6fe4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_p_values.npy', all_p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b650cf3",
   "metadata": {},
   "source": [
    "# MNIST digit change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_trained_model(device=\"cpu\"):\n",
    "    class MNISTModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MNISTModel, self).__init__()\n",
    "            self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = torch.nn.Dropout(0.25)\n",
    "            self.dropout2 = torch.nn.Dropout(0.5)\n",
    "            self.fc1 = torch.nn.Linear(9216, 128)\n",
    "            self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = torch.nn.functional.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    model = MNISTModel().to(device)\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "    train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Training MNIST model...\")\n",
    "    model.train()\n",
    "    for epoch in range(1):\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\n",
    "                    f\"Epoch: {epoch} [{batch_idx*len(data)}/{len(train_loader.dataset)} \"\n",
    "                    f\"({100. * batch_idx / len(train_loader):.0f}%)]\\\\tLoss: {loss.item():.6f}\"\n",
    "                )\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_digit(model, image, device=\"cpu\"):\n",
    "    image = image.reshape(1, 1, 28, 28)\n",
    "    image_tensor = torch.tensor(image, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = torch.softmax(model(image_tensor), dim=1).cpu()\n",
    "        predicted = outputs.argmax(dim=1).item()\n",
    "    return (predicted, outputs)\n",
    "\n",
    "\n",
    "def generate_mnist_dataset(length, changepoint, digit1=3, digit2=7):\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    data = mnist_data.data.numpy()\n",
    "    targets = mnist_data.targets.numpy()\n",
    "\n",
    "    images_digit1 = data[targets == digit1]\n",
    "    images_digit2 = data[targets == digit2]\n",
    "    np.random.shuffle(images_digit1)\n",
    "    np.random.shuffle(images_digit2)\n",
    "\n",
    "    n1 = changepoint + 1\n",
    "    n2 = length - n1\n",
    "    if n1 > len(images_digit1) or n2 > len(images_digit2):\n",
    "        raise ValueError(\"Insufficient images for the specified digits and length.\")\n",
    "\n",
    "    data1 = images_digit1[:n1]\n",
    "    data2 = images_digit2[:n2]\n",
    "    x = np.concatenate([data1, data2], axis=0)\n",
    "\n",
    "    x = x.reshape(length, -1).astype(np.float32) / 255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sequential_scores(x, model, device=\"cpu\"):\n",
    "    length = len(x)\n",
    "\n",
    "    print(\"Getting model predictions...\")\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for i in tqdm(range(length)):\n",
    "        pred, prob = predict_digit(model, x[i], device)\n",
    "        predictions.append(pred)\n",
    "        probabilities.append(prob.squeeze())\n",
    "\n",
    "    probabilities = torch.stack(probabilities)\n",
    "\n",
    "    left_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing left scores for each t\"):\n",
    "        reference = max(predictions[t+1:], key=predictions[t+1:].count)\n",
    "        for r in range(t + 1):\n",
    "            seen_digits = {}\n",
    "            for i in range(r + 1):\n",
    "                digit = predictions[i]\n",
    "                seen_digits[digit] = seen_digits.get(digit, 0) + 1\n",
    "\n",
    "            baseline_digit = max(seen_digits, key=seen_digits.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_digit]\n",
    "            left_scores[t, r] = prob_baseline / (probabilities[r, reference] + 1e-10)\n",
    "\n",
    "    right_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing right scores for each t\"):\n",
    "        reference = max(predictions[:t+1], key=predictions[:t+1].count)\n",
    "        for r in range(t + 1, length):\n",
    "            seen_digits = {}\n",
    "            for i in range(r, length):\n",
    "                digit = predictions[i]\n",
    "                seen_digits[digit] = seen_digits.get(digit, 0) + 1\n",
    "\n",
    "            baseline_digit = max(seen_digits, key=seen_digits.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_digit]\n",
    "            right_scores[t, r] = prob_baseline / (probabilities[r, reference] + 1e-10)\n",
    "\n",
    "    return left_scores, right_scores, predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601689df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mnist_simulation(n, xi):\n",
    "    x = generate_mnist_dataset(n, xi)\n",
    "    left_scores, right_scores, predictions, probabilities = compute_sequential_scores(\n",
    "        x, model\n",
    "    )\n",
    "    p_values = np.zeros(n - 1)\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t+1):\n",
    "            left_segment_scores = left_scores[t, : r + 1]\n",
    "            rank = np.sum(left_scores[t, r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[t, r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(n - 1, t, -1):\n",
    "            right_segment_scores = right_scores[t, r:]\n",
    "            rank = np.sum(right_scores[t, r] < right_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(right_scores[t, r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "p_values = run_mnist_simulation(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2147a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(\n",
    "    0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\"\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for MNIST digit change (digit classifier)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mnist-pvalues.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6862e3c",
   "metadata": {},
   "source": [
    "# SST-2 sentiment change (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_sentiment_model(device=\"cpu\"):\n",
    "    model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def generate_sentiment_dataset(length, changepoint, dataset_name=\"sst2\"):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    train_data = dataset[\"train\"]\n",
    "    positive_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 1]\n",
    "    negative_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 0]\n",
    "\n",
    "    random.shuffle(positive_texts)\n",
    "    random.shuffle(negative_texts)\n",
    "\n",
    "    n1 = changepoint + 1\n",
    "    n2 = length - n1\n",
    "\n",
    "    if n1 > len(positive_texts) or n2 > len(negative_texts):\n",
    "        raise ValueError(\"Insufficient texts for the specified length and changepoint.\")\n",
    "\n",
    "    texts_before = positive_texts[:n1]\n",
    "    texts_after = negative_texts[:n2]\n",
    "\n",
    "    texts = texts_before + texts_after\n",
    "    true_labels = [1] * n1 + [0] * n2\n",
    "\n",
    "    return texts, true_labels\n",
    "\n",
    "\n",
    "def generate_mixed_sentiment_dataset(length, changepoint, dataset_name=\"sst2\"):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    train_data = dataset[\"train\"]\n",
    "    positive_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 1]\n",
    "    negative_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 0]\n",
    "\n",
    "    random.shuffle(positive_texts)\n",
    "    random.shuffle(negative_texts)\n",
    "\n",
    "    n_pre = changepoint + 1\n",
    "    n_post = length - n_pre\n",
    "\n",
    "    n_pos_pre = int(n_pre * 0.6)\n",
    "    n_neg_pre = n_pre - n_pos_pre\n",
    "\n",
    "    n_pos_post = int(n_post * 0.4)\n",
    "    n_neg_post = n_post - n_pos_post\n",
    "\n",
    "    if n_pos_pre + n_pos_post > len(positive_texts) or n_neg_pre + n_neg_post > len(\n",
    "        negative_texts\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Insufficient texts for the specified distribution and length.\"\n",
    "        )\n",
    "\n",
    "    pre_pos_texts = positive_texts[:n_pos_pre]\n",
    "    pre_neg_texts = negative_texts[:n_neg_pre]\n",
    "    pre_texts = pre_pos_texts + pre_neg_texts\n",
    "    pre_labels = [1] * n_pos_pre + [0] * n_neg_pre\n",
    "\n",
    "    pre_combined = list(zip(pre_texts, pre_labels))\n",
    "    random.shuffle(pre_combined)\n",
    "    pre_texts, pre_labels = zip(*pre_combined)\n",
    "\n",
    "    post_pos_texts = positive_texts[n_pos_pre : n_pos_pre + n_pos_post]\n",
    "    post_neg_texts = negative_texts[n_neg_pre : n_neg_pre + n_neg_post]\n",
    "    post_texts = post_pos_texts + post_neg_texts\n",
    "    post_labels = [1] * n_pos_post + [0] * n_neg_post\n",
    "\n",
    "    post_combined = list(zip(post_texts, post_labels))\n",
    "    random.shuffle(post_combined)\n",
    "    post_texts, post_labels = zip(*post_combined)\n",
    "\n",
    "    texts = list(pre_texts) + list(post_texts)\n",
    "    true_labels = list(pre_labels) + list(post_labels)\n",
    "\n",
    "    return texts, true_labels\n",
    "\n",
    "\n",
    "def predict_sentiment(model, tokenizer, text, device=\"cpu\"):\n",
    "    inputs = tokenizer(\n",
    "        text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).cpu()\n",
    "        predicted = probs.argmax(dim=1).item()\n",
    "\n",
    "    return (predicted, probs.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc830d8c",
   "metadata": {},
   "source": [
    "## Plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af035cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "changepoint = 400\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, tokenizer = get_pretrained_sentiment_model(device)\n",
    "\n",
    "print(\"Generating sentiment dataset...\")\n",
    "texts, true_labels = generate_sentiment_dataset(length, changepoint)\n",
    "\n",
    "print(\"Getting predictions...\")\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "for i, text in enumerate(tqdm(texts)):\n",
    "    pred, prob = predict_sentiment(model, tokenizer, text, device)\n",
    "    predictions.append(pred)\n",
    "    probabilities.append(prob)\n",
    "\n",
    "probabilities = torch.stack(probabilities)\n",
    "\n",
    "print(\"\\nExamples before changepoint (positive):\")\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(0, changepoint)\n",
    "    print(f'Text {i+1}: \"{texts[idx]}\"')\n",
    "    print(\n",
    "        f\"True label: Positive, Predicted: {'Positive' if predictions[idx] == 1 else 'Negative'}\"\n",
    "    )\n",
    "    print(f\"Confidence: {probabilities[idx][predictions[idx]]:.4f}\\n\")\n",
    "\n",
    "print(\"\\nExamples after changepoint (negative):\")\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(changepoint + 1, length)\n",
    "    print(f'Text {i+1}: \"{texts[idx]}\"')\n",
    "    print(\n",
    "        f\"True label: Negative, Predicted: {'Positive' if predictions[idx] == 1 else 'Negative'}\"\n",
    "    )\n",
    "    print(f\"Confidence: {probabilities[idx][predictions[idx]]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43494506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sequential_sentiment_scores(texts, model, tokenizer, device=\"cpu\"):\n",
    "    length = len(texts)\n",
    "\n",
    "    print(\"Getting model predictions...\")\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for i, text in enumerate(tqdm(texts)):\n",
    "        pred, prob = predict_sentiment(model, tokenizer, text, device)\n",
    "        predictions.append(pred)\n",
    "        probabilities.append(prob)\n",
    "\n",
    "    probabilities = torch.stack(probabilities)\n",
    "\n",
    "    left_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing left scores for each t\"):\n",
    "        for r in range(t + 1):\n",
    "            seen_sentiments = {0: 0, 1: 0}\n",
    "            for i in range(r + 1):\n",
    "                sentiment = predictions[i]\n",
    "                seen_sentiments[sentiment] += 1\n",
    "\n",
    "            baseline_sentiment = max(seen_sentiments, key=seen_sentiments.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_sentiment]\n",
    "            left_scores[t, r] = prob_baseline / (1 - prob_baseline + 1e-10)\n",
    "\n",
    "    right_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing right scores for each t\"):\n",
    "        for r in range(t + 1, length):\n",
    "            seen_sentiments = {0: 0, 1: 0}\n",
    "            for i in range(r, length):\n",
    "                sentiment = predictions[i]\n",
    "                seen_sentiments[sentiment] += 1\n",
    "\n",
    "            baseline_sentiment = max(seen_sentiments, key=seen_sentiments.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_sentiment]\n",
    "            right_scores[t, r] = prob_baseline / (1 - prob_baseline + 1e-10)\n",
    "\n",
    "    return left_scores, right_scores, predictions, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4e30b",
   "metadata": {},
   "source": [
    "## Full sentiment change (pos. to neg.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sentiment_simulation(n, xi):\n",
    "    x, y = generate_sentiment_dataset(n, xi)\n",
    "    left_scores, right_scores, predictions, probabilities = compute_sequential_sentiment_scores(x, model, tokenizer, device)\n",
    "\n",
    "    p_values = np.zeros(n - 1)\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            left_segment_scores = left_scores[t, : r + 1]\n",
    "            rank = np.sum(left_scores[t, r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[t, r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            right_segment_scores = right_scores[t, r:]\n",
    "            rank = np.sum(\n",
    "                right_scores[t, r] < right_segment_scores\n",
    "            ) + np.random.uniform(0, 1) * np.sum(\n",
    "                right_scores[t, r] == right_segment_scores\n",
    "            )\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "p_values = run_sentiment_simulation(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eefefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for SST-2 sentiment change\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/sentiment-pvalues.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790001f",
   "metadata": {},
   "source": [
    "## Mixed sentiment change (60% pos. to 60% neg.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c276ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mixed_sentiment_simulation(n, xi):\n",
    "    x, y = generate_mixed_sentiment_dataset(n, xi)\n",
    "    left_scores, right_scores, predictions, probabilities = (\n",
    "        compute_sequential_sentiment_scores(x, model, tokenizer, device)\n",
    "    )\n",
    "\n",
    "    p_values = np.zeros(n - 1)\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            left_segment_scores = left_scores[t, : r + 1]\n",
    "            rank = np.sum(left_scores[t, r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[t, r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            right_segment_scores = right_scores[t, r:]\n",
    "            rank = np.sum(\n",
    "                right_scores[t, r] < right_segment_scores\n",
    "            ) + np.random.uniform(0, 1) * np.sum(\n",
    "                right_scores[t, r] == right_segment_scores\n",
    "            )\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "p_values = run_mixed_sentiment_simulation(n, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for SST-2 mixed sentiment change\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/sentiment-pvalues-mixed.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53a9f9",
   "metadata": {},
   "source": [
    "# Human Activity Dataset (HAD) change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e7f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_had_dataset():\n",
    "    import urllib.request\n",
    "    import zipfile\n",
    "    import os\n",
    "    \n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\"\n",
    "    \n",
    "    os.makedirs(\"./data\", exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(\"./data/UCI_HAR_Dataset.zip\"):\n",
    "        print(\"Downloading Human Activity Dataset...\")\n",
    "        urllib.request.urlretrieve(url, \"./data/UCI_HAR_Dataset.zip\")\n",
    "    \n",
    "    if not os.path.exists(\"./data/UCI HAR Dataset\"):\n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile(\"./data/UCI_HAR_Dataset.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./data\")\n",
    "    \n",
    "    train_file = \"./data/UCI HAR Dataset/train/X_train.txt\"\n",
    "    train_labels_file = \"./data/UCI HAR Dataset/train/y_train.txt\"\n",
    "    \n",
    "    if os.path.exists(train_file):\n",
    "        X_train = np.loadtxt(train_file)\n",
    "        y_train = np.loadtxt(train_labels_file)\n",
    "        \n",
    "        walking_indices = np.where(y_train == 1)[0]\n",
    "        sitting_indices = np.where(y_train == 4)[0]\n",
    "        \n",
    "        n_walking = min(400, len(walking_indices))\n",
    "        n_sitting = min(600, len(sitting_indices))\n",
    "        \n",
    "        if n_walking > 0 and n_sitting > 0:\n",
    "            selected_walking = walking_indices[:n_walking]\n",
    "            selected_sitting = sitting_indices[:n_sitting]\n",
    "            combined_indices = np.concatenate([selected_walking, selected_sitting])\n",
    "        \n",
    "            timeseries = X_train[combined_indices, 0]\n",
    "            true_changepoint = n_walking\n",
    "            \n",
    "            return timeseries, true_changepoint\n",
    "\n",
    "\n",
    "print(\"Loading Human Activity Dataset...\")\n",
    "timeseries, true_changepoint = load_had_dataset()\n",
    "\n",
    "n_had = len(timeseries)\n",
    "xi_had = true_changepoint\n",
    "\n",
    "print(f\"HAD Dataset loaded:\")\n",
    "print(f\"Total length: {n_had} samples\")\n",
    "print(f\"True changepoint: {xi_had} (activity transition)\")\n",
    "\n",
    "time_indices = np.arange(1, n_had + 1)\n",
    "plt.plot(time_indices, timeseries)\n",
    "plt.axvline(x=xi_had + 1, color=\"red\", linestyle=\"--\", label=f\"Changepoint ($\\\\xi = {xi_had}$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"Accelerometer reading\")\n",
    "plt.title(\"Human Activity Recognition accelerometer data\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/had-examples.pdf\")\n",
    "plt.show()\n",
    "\n",
    "pre_change = timeseries[:xi_had]\n",
    "post_change = timeseries[xi_had:]\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"Pre-change activity mean: {np.mean(pre_change):.3f}, std: {np.std(pre_change):.3f}\")\n",
    "print(f\"Post-change activity mean: {np.mean(post_change):.3f}, std: {np.std(post_change):.3f}\")\n",
    "print(f\"Mean difference: {np.mean(pre_change) - np.mean(post_change):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_had_simulation_kde():\n",
    "    n = len(timeseries)\n",
    "\n",
    "    p_values = np.zeros(n - 1)\n",
    "\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        left_scores = np.zeros(n)\n",
    "        right_scores = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            data_f0 = timeseries[: r + 1]\n",
    "            kde_f0 = compute_kde(data_f0)\n",
    "            f0_score = kde_f0(timeseries[r])\n",
    "\n",
    "            if t + 1 >= n:\n",
    "                left_scores[r] = 1.0\n",
    "                continue\n",
    "\n",
    "            data_f1 = timeseries[t + 1 :]\n",
    "            if len(data_f1) == 0:\n",
    "                left_scores[r] = 1.0\n",
    "                continue\n",
    "\n",
    "            kde_f1 = compute_kde(data_f1)\n",
    "            f1_score = kde_f1(timeseries[r])\n",
    "\n",
    "            left_scores[r] = f1_score / (\n",
    "                f0_score + 1e-10\n",
    "            )\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            data_f1 = timeseries[r:]\n",
    "            kde_f1 = compute_kde(data_f1)\n",
    "            f1_score = kde_f1(timeseries[r])\n",
    "\n",
    "            data_f0 = timeseries[: t + 1]\n",
    "            kde_f0 = compute_kde(data_f0)\n",
    "            f0_score = kde_f0(timeseries[r])\n",
    "\n",
    "            right_scores[r] = f0_score / (f1_score + 1e-10)\n",
    "\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            left_segment_scores = left_scores[: r + 1]\n",
    "            rank = np.sum(left_scores[r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(t + 1, n):\n",
    "            right_segment_scores = right_scores[r:]\n",
    "            rank = np.sum(right_scores[r] < right_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(right_scores[r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        try:\n",
    "            if t > 0:\n",
    "                p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[\n",
    "                    1\n",
    "                ]\n",
    "            else:\n",
    "                p_left = 1.0\n",
    "\n",
    "            if t + 1 < n:\n",
    "                p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[\n",
    "                    1\n",
    "                ]\n",
    "            else:\n",
    "                p_right = 1.0\n",
    "        except:\n",
    "            p_left = 1.0\n",
    "            p_right = 1.0\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "p_values = run_had_simulation_kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c9cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n_had)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi_had + 1, color=\"red\", linestyle=\"--\", label=f\"Changepoint ($\\\\xi = {xi_had}$)\")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for HAR activity change\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(\"images/had-pvalues.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue changepoint: {xi_had + 1} (activity transition)\")\n",
    "print(f\"Detected changepoint: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - (xi_had + 1))} samples\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi_had-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5fd56",
   "metadata": {},
   "source": [
    "# CIFAR-100 class change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar100_pretrained_model(device=\"cpu\"):\n",
    "    import detectors\n",
    "    import timm\n",
    "    print(\"Loading pretrained ResNet18 model from timm and adapting for CIFAR-100...\")\n",
    "    \n",
    "    model = timm.create_model(\"resnet18_cifar100\", pretrained=True, num_classes=100)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cifar100_class(model, image, device=\"cpu\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = image.unsqueeze(0)\n",
    "    elif len(image.shape) == 4 and image.shape[0] != 1:\n",
    "        image = image[:1]\n",
    "    \n",
    "    image_tensor = image.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = torch.softmax(model(image_tensor), dim=1).cpu()\n",
    "        predicted = outputs.argmax(dim=1).item()\n",
    "    \n",
    "    return (predicted, outputs.squeeze())\n",
    "\n",
    "\n",
    "def generate_cifar100_dataset(length, changepoint, class1=15, class2=47):\n",
    "    from torchvision.datasets import CIFAR100\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "    ])\n",
    "    \n",
    "    train_data = CIFAR100(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_data = CIFAR100(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    \n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(train_data)):\n",
    "        image, label = train_data[i]\n",
    "        all_images.append(image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        image, label = test_data[i]\n",
    "        all_images.append(image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    class1_indices = [i for i, label in enumerate(all_labels) if label == class1]\n",
    "    class2_indices = [i for i, label in enumerate(all_labels) if label == class2]\n",
    "    \n",
    "    np.random.shuffle(class1_indices)\n",
    "    np.random.shuffle(class2_indices)\n",
    "    \n",
    "    n1 = changepoint + 1\n",
    "    n2 = length - n1\n",
    "    \n",
    "    selected_indices = class1_indices[:n1] + class2_indices[:n2]\n",
    "    selected_images = [all_images[i] for i in selected_indices]\n",
    "    \n",
    "    return torch.stack(selected_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sequential_cifar100_scores(x, model, device=\"cpu\"):\n",
    "    length = len(x)\n",
    "\n",
    "    print(\"Getting CIFAR-100 model predictions...\")\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for i in tqdm(range(length)):\n",
    "        pred, prob = predict_cifar100_class(model, x[i], device)\n",
    "        predictions.append(pred)\n",
    "        probabilities.append(prob)\n",
    "\n",
    "    probabilities = torch.stack(probabilities)\n",
    "\n",
    "    left_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing left scores for each t\"):\n",
    "        reference = max(predictions[t+1:], key=predictions[t+1:].count)\n",
    "        for r in range(t + 1):\n",
    "            seen_classes = {}\n",
    "            for i in range(r + 1):\n",
    "                class_label = predictions[i]\n",
    "                seen_classes[class_label] = seen_classes.get(class_label, 0) + 1\n",
    "\n",
    "            baseline_class = max(seen_classes, key=seen_classes.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_class]\n",
    "            left_scores[t, r] = prob_baseline / (probabilities[r, reference] + 1e-10)\n",
    "\n",
    "    right_scores = np.zeros((length - 1, length))\n",
    "\n",
    "    for t in tqdm(range(length - 1), desc=\"Computing right scores for each t\"):\n",
    "        reference = max(predictions[:t+1], key=predictions[:t+1].count)\n",
    "        for r in range(t + 1, length):\n",
    "            seen_classes = {}\n",
    "            for i in range(r, length):\n",
    "                class_label = predictions[i]\n",
    "                seen_classes[class_label] = seen_classes.get(class_label, 0) + 1\n",
    "\n",
    "            baseline_class = max(seen_classes, key=seen_classes.get)\n",
    "\n",
    "            prob_baseline = probabilities[r, baseline_class]\n",
    "            right_scores[t, r] = prob_baseline / (probabilities[r, reference] + 1e-10)\n",
    "\n",
    "    return left_scores, right_scores, predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "cifar100_dataset = CIFAR100(root=\"./data\", train=False, download=True)\n",
    "class_names = cifar100_dataset.classes\n",
    "\n",
    "print(\"CIFAR-100 class names:\")\n",
    "print(f\"Class 3: {class_names[3]}\")\n",
    "print(f\"Class 4: {class_names[4]}\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = CIFAR100(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_data = CIFAR100(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "class3_count_train = sum(1 for _, label in train_data if label == 3)\n",
    "class4_count_train = sum(1 for _, label in train_data if label == 4)\n",
    "class3_count_test = sum(1 for _, label in test_data if label == 3)\n",
    "class4_count_test = sum(1 for _, label in test_data if label == 4)\n",
    "\n",
    "print(\n",
    "    f\"\\nClass 3 ({class_names[3]}) - Train: {class3_count_train}, Test: {class4_count_test}, Total: {class3_count_train + class3_count_test}\"\n",
    ")\n",
    "print(\n",
    "    f\"Class 4 ({class_names[4]}) - Train: {class4_count_train}, Test: {class4_count_test}, Total: {class4_count_train + class4_count_test}\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_cifar100_dataset_fixed(length, changepoint, class1=3, class2=4):\n",
    "    from torchvision.datasets import CIFAR100\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_data = CIFAR100(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_data = CIFAR100(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    class1_images = []\n",
    "    class1_labels = []\n",
    "\n",
    "    for _, (image, label) in enumerate(train_data):\n",
    "        if label == class1:\n",
    "            class1_images.append(image)\n",
    "            class1_labels.append(label)\n",
    "\n",
    "    for _, (image, label) in enumerate(test_data):\n",
    "        if label == class1:\n",
    "            class1_images.append(image)\n",
    "            class1_labels.append(label)\n",
    "\n",
    "    class2_images = []\n",
    "    class2_labels = []\n",
    "\n",
    "    for _, (image, label) in enumerate(train_data):\n",
    "        if label == class2:\n",
    "            class2_images.append(image)\n",
    "            class2_labels.append(label)\n",
    "\n",
    "    for _, (image, label) in enumerate(test_data):\n",
    "        if label == class2:\n",
    "            class2_images.append(image)\n",
    "            class2_labels.append(label)\n",
    "\n",
    "    np.random.shuffle(class1_images)\n",
    "    np.random.shuffle(class2_images)\n",
    "\n",
    "    n1 = changepoint + 1\n",
    "    n2 = length - n1\n",
    "\n",
    "    selected_class1 = class1_images[:n1]\n",
    "    selected_class2 = class2_images[:n2]\n",
    "\n",
    "    all_images = selected_class1 + selected_class2\n",
    "    all_labels = [class1] * n1 + [class2] * n2\n",
    "\n",
    "    print(f\"Generated dataset: {len(all_images)} images\")\n",
    "    print(f\"First {n1} images are class {class1} ({class_names[class1]})\")\n",
    "    print(f\"Last {n2} images are class {class2} ({class_names[class2]})\")\n",
    "\n",
    "    actual_labels_start = all_labels[:5]\n",
    "    actual_labels_end = all_labels[-5:]\n",
    "    print(f\"First 5 labels: {actual_labels_start}\")\n",
    "    print(f\"Last 5 labels: {actual_labels_end}\")\n",
    "\n",
    "    return torch.stack(all_images), all_labels\n",
    "\n",
    "\n",
    "x_fixed, labels_fixed = generate_cifar100_dataset_fixed(n, xi, class1=3, class2=4)\n",
    "print(f\"\\nSuccessfully generated dataset with shape: {x_fixed.shape}\")\n",
    "\n",
    "def show_cifar100_examples_with_labels(x, labels, changepoint, n_examples=3):\n",
    "    mean = torch.tensor([0.5071, 0.4867, 0.4408])\n",
    "    std = torch.tensor([0.2675, 0.2565, 0.2761])\n",
    "\n",
    "    def denormalize_image(tensor):\n",
    "        denorm = tensor * std[:, None, None] + mean[:, None, None]\n",
    "        return torch.clamp(denorm, 0, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "    class_names = CIFAR100(root=\"./data\", train=False, download=True).classes\n",
    "\n",
    "    time_points = [398, 399, 400]\n",
    "    titles_before = [r\"$t = 398$\", r\"$t = 399$\", r\"$t = \\xi = 400$\"]\n",
    "\n",
    "    for i, (t, title) in enumerate(zip(time_points, titles_before)):\n",
    "        idx = t - 1\n",
    "        img_denorm = denormalize_image(x[idx])\n",
    "        actual_class = labels[idx]\n",
    "        class_name = class_names[actual_class]\n",
    "\n",
    "        axes[i].imshow(img_denorm.permute(1, 2, 0).numpy())\n",
    "        axes[i].set_title(f\"{title}\\n{class_name}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    post_change_points = [401, 402]\n",
    "    titles_after = [r\"$t = 401$\", r\"$t = 402$\"]\n",
    "\n",
    "    for i, (t, title) in enumerate(zip(post_change_points, titles_after)):\n",
    "        idx = t - 1\n",
    "        img_denorm = denormalize_image(x[idx])\n",
    "        actual_class = labels[idx]\n",
    "        class_name = class_names[actual_class]\n",
    "\n",
    "        axes[i + 3].imshow(img_denorm.permute(1, 2, 0).numpy())\n",
    "        axes[i + 3].set_title(f\"{title}\\n{class_name}\")\n",
    "        axes[i + 3].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"images/cifar100-examples.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "show_cifar100_examples_with_labels(x_fixed, labels_fixed, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "cifar100_model = get_cifar100_pretrained_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c34984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cifar = 800\n",
    "xi_cifar = 300\n",
    "\n",
    "print(f\"CIFAR-100 simulation parameters:\")\n",
    "print(f\"Total length: {n_cifar}\")\n",
    "print(f\"Changepoint: {xi_cifar}\")\n",
    "print(f\"Pre-change images needed: {xi_cifar + 1}\")\n",
    "print(f\"Post-change images needed: {n_cifar - xi_cifar - 1}\")\n",
    "print(f\"Available per class: ~600 (500 train + 100 test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf17f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cifar100_simulation(n, xi, class1=15, class2=47):\n",
    "    x = generate_cifar100_dataset(n, xi, class1, class2)\n",
    "    left_scores, right_scores, predictions, probabilities = compute_sequential_cifar100_scores(\n",
    "        x, cifar100_model, device\n",
    "    )\n",
    "    p_values = np.zeros(n - 1)\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p_values_curr = np.zeros(n)\n",
    "\n",
    "        for r in range(t+1):\n",
    "            left_segment_scores = left_scores[t, : r + 1]\n",
    "            rank = np.sum(left_scores[t, r] < left_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(left_scores[t, r] == left_segment_scores)\n",
    "            p_values_curr[r] = rank / (r + 1)\n",
    "\n",
    "        for r in range(n - 1, t, -1):\n",
    "            right_segment_scores = right_scores[t, r:]\n",
    "            rank = np.sum(right_scores[t, r] < right_segment_scores) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(right_scores[t, r] == right_segment_scores)\n",
    "            p_values_curr[r] = rank / (n - r)\n",
    "\n",
    "        p_left = ks_1samp(p_values_curr[: t + 1], uniform.cdf, method=\"exact\")[1]\n",
    "        p_right = ks_1samp(p_values_curr[t + 1 :], uniform.cdf, method=\"exact\")[1]\n",
    "\n",
    "        p_values[t] = 1 - (1 - min(p_left, p_right)) ** 2\n",
    "\n",
    "    return p_values\n",
    "\n",
    "p_values = run_cifar100_simulation(n_cifar, xi_cifar, class1=3, class2=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_indices_p = np.arange(1, n_cifar)\n",
    "plt.plot(time_indices_p, p_values)\n",
    "plt.axvline(x=xi_cifar, color=\"red\", linestyle=\"--\", label=f\"Changepoint ($\\\\xi = {xi_cifar}$)\")\n",
    "plt.axhline(\n",
    "    0.05, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\"\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.title(\"p-values for CIFAR-100 class change (pretrained model)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/cifar100-pvalues.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "detected_changepoint = np.argmax(p_values) + 1\n",
    "print(f\"\\nTrue change point: {xi_cifar}\")\n",
    "print(f\"Detected change point: {detected_changepoint}\")\n",
    "print(f\"Detection error: {abs(detected_changepoint - xi_cifar)}\")\n",
    "print(f\"Size of confidence set: {np.sum(p_values > 0.05)}\")\n",
    "print(f\"Changepoint in confidence set: {p_values[xi_cifar-1] > 0.05}\")\n",
    "print(f\"CI: {np.where(p_values > 0.05)[0] + 1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

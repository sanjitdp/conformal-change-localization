{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc1cb82",
   "metadata": {},
   "source": [
    "# Conformal changepoint localization (CONCH) experiments\n",
    "\n",
    "This notebook implements the CONCH algorithm for changepoint localization. We apply our algorithm to image data from MNIST, text data from SST-2, and a Gaussian mean change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, ks_1samp, uniform\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a61947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\n",
    "    \"svg\"\n",
    ")\n",
    "plt.style.use(\"math.mplstyle\")\n",
    "\n",
    "plt.rcParams.update({\"axes.labelsize\": 14})\n",
    "plt.rcParams.update({\"xtick.labelsize\": 14})\n",
    "plt.rcParams.update({\"ytick.labelsize\": 14})\n",
    "plt.rcParams.update({\"legend.fontsize\": 14})\n",
    "plt.rcParams.update({\"axes.titlesize\": 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca66c26",
   "metadata": {},
   "source": [
    "## MNIST simulation\n",
    "\n",
    "CONCH algorithm applied to an image dataset with digit 3 before the changepoint and digit 7 after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a23210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(device=\"cpu\"):\n",
    "    model = torch.hub.load(\n",
    "        \"pytorch/vision:v0.10.0\", \"resnet18\", weights=ResNet18_Weights.IMAGENET1K_V1\n",
    "    )\n",
    "\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        1, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "    )\n",
    "\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_mnist_trained_model(device=\"cpu\"):\n",
    "    class MNISTModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MNISTModel, self).__init__()\n",
    "            self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = torch.nn.Dropout(0.25)\n",
    "            self.dropout2 = torch.nn.Dropout(0.5)\n",
    "            self.fc1 = torch.nn.Linear(9216, 128)\n",
    "            self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = torch.nn.functional.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    model = MNISTModel().to(device)\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "    train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Training MNIST model...\")\n",
    "    model.train()\n",
    "    for epoch in range(1):\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\n",
    "                    f\"Epoch: {epoch} [{batch_idx*len(data)}/{len(train_loader.dataset)} \"\n",
    "                    f\"({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\"\n",
    "                )\n",
    "\n",
    "    test_dataset = MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    print(f\"Test accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_digit(model, image, device=\"cpu\"):\n",
    "    image = image.reshape(1, 1, 28, 28)\n",
    "    image_tensor = torch.tensor(image, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = torch.softmax(model(image_tensor), dim=1).cpu()\n",
    "        predicted = outputs.argmax(dim=1).item()\n",
    "    return (predicted, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mnist_dataset(length, changepoint, digit1=3, digit2=7):\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_data = MNIST(\n",
    "        root=\"./data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    data = mnist_data.data.numpy()\n",
    "    targets = mnist_data.targets.numpy()\n",
    "    \n",
    "    images_digit1 = data[targets == digit1]\n",
    "    images_digit2 = data[targets == digit2]\n",
    "    np.random.shuffle(images_digit1)\n",
    "    np.random.shuffle(images_digit2)\n",
    "    \n",
    "    n1 = changepoint + 1\n",
    "    n2 = length - n1\n",
    "    if n1 > len(images_digit1) or n2 > len(images_digit2):\n",
    "        raise ValueError(\"Insufficient images for the specified digits and length.\")\n",
    "        \n",
    "    data1 = images_digit1[:n1]\n",
    "    data2 = images_digit2[:n2]\n",
    "    x = np.concatenate([data1, data2], axis=0)\n",
    "    \n",
    "    x = x.reshape(length, -1).astype(np.float32) / 255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrepancy_scores(x, scores_left, scores_right):\n",
    "    discrepancy_scores = np.empty(len(x) - 1)\n",
    "    statistics = []\n",
    "    for t in tqdm(range(len(x) - 1)):\n",
    "        p = np.empty(len(x))\n",
    "        for r in range(t + 1):\n",
    "            p[r] = (\n",
    "                np.count_nonzero(scores_left[t, : r + 1] > scores_left[t, r])\n",
    "                + np.random.uniform(0, 1) * np.count_nonzero(scores_left[t, : r + 1] == scores_left[t, r])\n",
    "            ) / (r + 1)\n",
    "        for r in range(len(x) - 1, t, -1):\n",
    "            p[r] = (\n",
    "                np.count_nonzero(scores_right[t, r:] > scores_right[t, r])\n",
    "                + np.random.uniform(0, 1) * np.count_nonzero(scores_right[t, r:] == scores_right[t, r])\n",
    "            ) / (len(x) - r)\n",
    "        statistics.append((ks_1samp(p[: t + 1], uniform.cdf), ks_1samp(p[t+1:], uniform.cdf)))\n",
    "        discrepancy_scores[t] = (\n",
    "            statistics[-1][0].statistic * np.sqrt(t + 1)\n",
    "            + statistics[-1][1].statistic * np.sqrt(len(x) - t - 1)\n",
    "        )\n",
    "    return discrepancy_scores, statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85536b",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "changepoint = 400\n",
    "digit1 = 3\n",
    "digit2 = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9f3d6",
   "metadata": {},
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11922626",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generate_mnist_dataset(length, changepoint, digit1, digit2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(6, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = changepoint - 2 + i\n",
    "    img = x[idx].reshape(28, 28)\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    if i != 2:\n",
    "        ax.set_title(f\"$t = {idx}$\")\n",
    "    else:\n",
    "        ax.set_title(f\"$t = \\\\xi = {idx}$\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/mnist-sample.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a2971",
   "metadata": {},
   "source": [
    "### Digit classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195be2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnist_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab487af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generate_mnist_dataset(length, changepoint, digit1, digit2)\n",
    "\n",
    "predicted_digits = [predict_digit(model, x[i]) for i in tqdm(range(length))]\n",
    "probabilities = torch.vstack([prob for _, prob in predicted_digits])\n",
    "\n",
    "left_score = np.zeros((length, length))\n",
    "seen_digits = {}\n",
    "for t, (predicted, _) in enumerate(predicted_digits):\n",
    "    if predicted in seen_digits:\n",
    "        seen_digits[predicted] += 1\n",
    "    else:\n",
    "        seen_digits[predicted] = 1\n",
    "    curr_digit = max(seen_digits, key=seen_digits.get)\n",
    "    left_score[t, : t + 1] = probabilities[: t + 1, curr_digit].cpu() / (\n",
    "        1 - probabilities[: t + 1, curr_digit].cpu()\n",
    "    )\n",
    "\n",
    "right_score = np.zeros((length, length))\n",
    "seen_digits = {}\n",
    "for i, (predicted, _) in enumerate(reversed(predicted_digits)):\n",
    "    t = length - i - 1\n",
    "    if predicted in seen_digits:\n",
    "        seen_digits[predicted] += 1\n",
    "    else:\n",
    "        seen_digits[predicted] = 1\n",
    "    curr_digit = max(seen_digits, key=seen_digits.get)\n",
    "    right_score[t, t:] = probabilities[t:, curr_digit].cpu() / (\n",
    "        1 - probabilities[t:, curr_digit].cpu()\n",
    "    )\n",
    "\n",
    "discrepancy_scores, statistics = get_discrepancy_scores(x, left_score, right_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df2ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "p_values_left = np.array([s[0].pvalue for s in statistics])\n",
    "p_values_right = np.array([s[1].pvalue for s in statistics])\n",
    "\n",
    "min_method = chi2.cdf(np.minimum(2 * p_values_left, 2 * p_values_right, np.ones_like(p_values_left)), 4)\n",
    "threshold = 0.05\n",
    "\n",
    "plt.plot(np.arange(1, length), min_method)\n",
    "plt.axvline(\n",
    "    changepoint, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\"\n",
    ")\n",
    "plt.axhline(threshold, color='green', linestyle=':', label='Threshold ($\\\\alpha = 0.05$)')\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\"p-values for MNIST digit change (digit classifier)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mnist-pvalues.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_set = np.argwhere(min_method > threshold).flatten()\n",
    "confidence_interval = (confidence_set[0], confidence_set[-1]) if len(confidence_set) > 0 else None\n",
    "\n",
    "print(f\"True changepoint: {changepoint}\")\n",
    "print(f\"Confidence interval: {confidence_interval}\")\n",
    "print(f\"Maximum p-value at t={np.argmax(min_method)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2d554",
   "metadata": {},
   "source": [
    "### Pre-trained ResNet-18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec397042",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = get_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "changepoint = 400\n",
    "digit1 = 3\n",
    "digit2 = 7\n",
    "\n",
    "x = generate_mnist_dataset(length, changepoint, digit1, digit2)\n",
    "\n",
    "predicted_digits = [predict_digit(pretrained_model, x[i]) for i in tqdm(range(length))]\n",
    "probabilities = torch.vstack([prob for _, prob in predicted_digits])\n",
    "\n",
    "left_score = np.zeros((length, length))\n",
    "seen_digits = {}\n",
    "for t, (predicted, _) in enumerate(predicted_digits):\n",
    "    if predicted in seen_digits:\n",
    "        seen_digits[predicted] += 1\n",
    "    else:\n",
    "        seen_digits[predicted] = 1\n",
    "    curr_digit = max(seen_digits, key=seen_digits.get)\n",
    "    left_score[t, : t + 1] = probabilities[: t + 1, curr_digit].cpu() / (\n",
    "        1 - probabilities[: t + 1, curr_digit].cpu()\n",
    "    )\n",
    "\n",
    "right_score = np.zeros((length, length))\n",
    "seen_digits = {}\n",
    "for i, (predicted, _) in enumerate(reversed(predicted_digits)):\n",
    "    t = length - i - 1\n",
    "    if predicted in seen_digits:\n",
    "        seen_digits[predicted] += 1\n",
    "    else:\n",
    "        seen_digits[predicted] = 1\n",
    "    curr_digit = max(seen_digits, key=seen_digits.get)\n",
    "    right_score[t, t:] = probabilities[t:, curr_digit].cpu() / (\n",
    "        1 - probabilities[t:, curr_digit].cpu()\n",
    "    )\n",
    "\n",
    "discrepancy_scores, statistics = get_discrepancy_scores(x, left_score, right_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "p_values_left = np.array([s[0].pvalue for s in statistics])\n",
    "p_values_right = np.array([s[1].pvalue for s in statistics])\n",
    "\n",
    "min_method_pretrained = chi2.cdf(np.minimum(2 * p_values_left, 2 * p_values_right, np.ones_like(p_values_left)), 4)\n",
    "threshold = 0.05\n",
    "\n",
    "plt.plot(np.arange(1, length), min_method_pretrained)\n",
    "plt.axvline(\n",
    "    changepoint, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\"\n",
    ")\n",
    "plt.axhline(threshold, color='green', linestyle=':', label='Threshold ($\\\\alpha = 0.05$)')\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\"p-values for MNIST digit change (pre-trained classifier)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mnist-pretrained.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf54db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_set = np.argwhere(min_method_pretrained > threshold).flatten()\n",
    "confidence_interval = (confidence_set[0], confidence_set[-1]) if len(confidence_set) > 0 else None\n",
    "\n",
    "print(f\"True changepoint: {changepoint}\")\n",
    "print(f\"Confidence interval: {confidence_interval}\")\n",
    "print(f\"Maximum p-value at t={np.argmax(min_method)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a209391",
   "metadata": {},
   "source": [
    "### Two-sided calibration with certified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_extended_mnist_dataset(\n",
    "    length, changepoint, calibration_size=100, digit1=3, digit2=7\n",
    "):\n",
    "    \"\"\"Generate MNIST dataset with a changepoint and calibration data.\"\"\"\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    data = mnist_data.data.numpy()\n",
    "    targets = mnist_data.targets.numpy()\n",
    "\n",
    "    images_digit1 = data[targets == digit1]\n",
    "    images_digit2 = data[targets == digit2]\n",
    "    np.random.shuffle(images_digit1)\n",
    "    np.random.shuffle(images_digit2)\n",
    "\n",
    "    n1 = changepoint + 1 + calibration_size\n",
    "    n2 = (length - changepoint - 1) + calibration_size\n",
    "\n",
    "    if n1 > len(images_digit1) or n2 > len(images_digit2):\n",
    "        raise ValueError(\"Insufficient images for the specified digits and length.\")\n",
    "\n",
    "    data1 = images_digit1[:n1]\n",
    "    data2 = images_digit2[:n2]\n",
    "\n",
    "    calibration_pre = data1[:calibration_size]\n",
    "    main_pre = data1[calibration_size:n1]\n",
    "    calibration_post = data2[:calibration_size]\n",
    "    main_post = data2[calibration_size:n2]\n",
    "\n",
    "    x_main = np.concatenate([main_pre, main_post], axis=0)\n",
    "    x_calibration_pre = calibration_pre\n",
    "    x_calibration_post = calibration_post\n",
    "\n",
    "    x_main = x_main.reshape(length, -1).astype(np.float32) / 255.0\n",
    "    x_calibration_pre = (\n",
    "        x_calibration_pre.reshape(calibration_size, -1).astype(np.float32) / 255.0\n",
    "    )\n",
    "    x_calibration_post = (\n",
    "        x_calibration_post.reshape(calibration_size, -1).astype(np.float32) / 255.0\n",
    "    )\n",
    "\n",
    "    return x_main, x_calibration_pre, x_calibration_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7813e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_size = 100\n",
    "\n",
    "def compute_left_scores_with_calibration(\n",
    "    probabilities, predicted_digits, probabilities_cal_pre, predicted_cal_pre, length\n",
    "):\n",
    "    left_scores = np.zeros((length, length))\n",
    "    left_scores_cal = np.zeros((length, calibration_size))\n",
    "\n",
    "    seen_digits = {}\n",
    "\n",
    "    for i, (predicted, _) in enumerate(predicted_cal_pre):\n",
    "        if predicted in seen_digits:\n",
    "            seen_digits[predicted] += 1\n",
    "        else:\n",
    "            seen_digits[predicted] = 1\n",
    "\n",
    "    for t, (predicted, _) in enumerate(predicted_digits):\n",
    "        if predicted in seen_digits:\n",
    "            seen_digits[predicted] += 1\n",
    "        else:\n",
    "            seen_digits[predicted] = 1\n",
    "        curr_digit = max(seen_digits, key=seen_digits.get)\n",
    "\n",
    "        left_scores[t, : t + 1] = probabilities[: t + 1, curr_digit].cpu() / (\n",
    "            1 - probabilities[: t + 1, curr_digit].cpu()\n",
    "        )\n",
    "\n",
    "        left_scores_cal[t, :] = probabilities_cal_pre[:, curr_digit].cpu() / (\n",
    "            1 - probabilities_cal_pre[:, curr_digit].cpu()\n",
    "        )\n",
    "\n",
    "    return left_scores, left_scores_cal\n",
    "\n",
    "\n",
    "def compute_right_scores_with_calibration(\n",
    "    probabilities, predicted_digits, probabilities_cal_post, predicted_cal_post, length\n",
    "):\n",
    "    calibration_size = len(\n",
    "        predicted_cal_post\n",
    "    )\n",
    "    right_scores = np.zeros((length, length))\n",
    "    right_scores_cal = np.zeros((length, calibration_size))\n",
    "\n",
    "    seen_digits = {}\n",
    "\n",
    "    for i, (predicted, _) in enumerate(predicted_cal_post):\n",
    "        if predicted in seen_digits:\n",
    "            seen_digits[predicted] += 1\n",
    "        else:\n",
    "            seen_digits[predicted] = 1\n",
    "\n",
    "    for i, (predicted, _) in enumerate(reversed(predicted_digits)):\n",
    "        t = length - i - 1\n",
    "        if predicted in seen_digits:\n",
    "            seen_digits[predicted] += 1\n",
    "        else:\n",
    "            seen_digits[predicted] = 1\n",
    "        curr_digit = max(seen_digits, key=seen_digits.get)\n",
    "\n",
    "        right_scores[t, t:] = probabilities[t:, curr_digit].cpu() / (\n",
    "            1 - probabilities[t:, curr_digit].cpu()\n",
    "        )\n",
    "\n",
    "        right_scores_cal[t, :] = probabilities_cal_post[:, curr_digit].cpu() / (\n",
    "            1 - probabilities_cal_post[:, curr_digit].cpu()\n",
    "        )\n",
    "\n",
    "    return right_scores, right_scores_cal\n",
    "\n",
    "\n",
    "def get_discrepancy_scores_with_calibration(\n",
    "    x, scores_left, scores_right, scores_left_cal, scores_right_cal\n",
    "):\n",
    "    n = len(x)\n",
    "    calibration_size_pre = scores_left_cal.shape[1]\n",
    "    calibration_size_post = scores_right_cal.shape[1]\n",
    "    discrepancy_scores = np.empty(n - 1)\n",
    "    statistics = []\n",
    "\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p = np.empty(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            score_r = scores_left[t, r]\n",
    "\n",
    "            main_counts = np.sum(scores_left[t, : r + 1] < score_r) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(scores_left[t, : r + 1] == score_r)\n",
    "\n",
    "            cal_counts = np.sum(scores_left_cal[t, :] < score_r) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(scores_left_cal[t, :] == score_r)\n",
    "\n",
    "            p[r] = (main_counts + cal_counts) / (r + 1 + calibration_size_pre)\n",
    "\n",
    "        for r in range(n - 1, t, -1):\n",
    "            score_r = scores_right[t, r]\n",
    "\n",
    "            main_counts = np.sum(scores_right[t, r:] < score_r) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(scores_right[t, r:] == score_r)\n",
    "\n",
    "            cal_counts = np.sum(scores_right_cal[t, :] < score_r) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(scores_right_cal[t, :] == score_r)\n",
    "\n",
    "            p[r] = (main_counts + cal_counts) / (n - r + calibration_size_post)\n",
    "\n",
    "        statistics.append(\n",
    "            (ks_1samp(p[: t + 1], uniform.cdf), ks_1samp(p[t + 1 :], uniform.cdf))\n",
    "        )\n",
    "        discrepancy_scores[t] = statistics[-1][0].statistic * np.sqrt(\n",
    "            t + 1\n",
    "        ) + statistics[-1][1].statistic * np.sqrt(n - t - 1)\n",
    "\n",
    "    return discrepancy_scores, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_main, x_cal_pre, x_cal_post = generate_extended_mnist_dataset(\n",
    "    length, changepoint, calibration_size, digit1, digit2\n",
    ")\n",
    "\n",
    "predicted_digits = [predict_digit(model, x_main[i]) for i in tqdm(range(length))]\n",
    "probabilities = torch.vstack([prob for _, prob in predicted_digits])\n",
    "\n",
    "predicted_cal_pre = [\n",
    "    predict_digit(model, x_cal_pre[i]) for i in tqdm(range(calibration_size))\n",
    "]\n",
    "probabilities_cal_pre = torch.vstack([prob for _, prob in predicted_cal_pre])\n",
    "\n",
    "predicted_cal_post = [\n",
    "    predict_digit(model, x_cal_post[i]) for i in tqdm(range(calibration_size))\n",
    "]\n",
    "probabilities_cal_post = torch.vstack([prob for _, prob in predicted_cal_post])\n",
    "\n",
    "left_scores, left_scores_cal = compute_left_scores_with_calibration(\n",
    "    probabilities, predicted_digits, probabilities_cal_pre, predicted_cal_pre, length\n",
    ")\n",
    "\n",
    "right_scores, right_scores_cal = compute_right_scores_with_calibration(\n",
    "    probabilities, predicted_digits, probabilities_cal_post, predicted_cal_post, length\n",
    ")\n",
    "\n",
    "discrepancy_scores_cal, statistics_cal = get_discrepancy_scores_with_calibration(\n",
    "    x_main, left_scores, right_scores, left_scores_cal, right_scores_cal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "p_values_left = np.array([s[0].pvalue for s in statistics_cal])\n",
    "p_values_right = np.array([s[1].pvalue for s in statistics_cal])\n",
    "\n",
    "min_method = chi2.cdf(\n",
    "    np.minimum(2 * p_values_left, 2 * p_values_right, np.ones_like(p_values_left)), 4\n",
    ")\n",
    "threshold = 0.05\n",
    "\n",
    "plt.plot(np.arange(1, length), min_method)\n",
    "plt.axvline(\n",
    "    changepoint, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\"\n",
    ")\n",
    "plt.axhline(\n",
    "    threshold, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\"\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\"p-values for MNIST digit change (two-sided calibration)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mnist-pvalues-calibrated.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2303a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = np.argwhere(min_method > threshold).flatten()\n",
    "confidence_interval = (ci[0], ci[-1]) if len(ci) > 0 else None\n",
    "print(f\"True changepoint: {changepoint}\")\n",
    "print(f\"Confidence interval: {confidence_interval}\")\n",
    "print(f\"Maximum p-value at t={np.argmax(min_method)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62e19f",
   "metadata": {},
   "source": [
    "### Left-sided calibration with certified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a100a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_left_calibration_mnist_dataset(\n",
    "    length, changepoint, calibration_size=100, digit1=3, digit2=7\n",
    "):\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    data = mnist_data.data.numpy()\n",
    "    targets = mnist_data.targets.numpy()\n",
    "\n",
    "    images_digit1 = data[targets == digit1]\n",
    "    images_digit2 = data[targets == digit2]\n",
    "    np.random.shuffle(images_digit1)\n",
    "    np.random.shuffle(images_digit2)\n",
    "\n",
    "    n1 = changepoint + 1 + calibration_size\n",
    "    n2 = length - changepoint - 1\n",
    "\n",
    "    if n1 > len(images_digit1) or n2 > len(images_digit2):\n",
    "        raise ValueError(\"Insufficient images for the specified digits and length.\")\n",
    "\n",
    "    data1 = images_digit1[:n1]\n",
    "    data2 = images_digit2[:n2]\n",
    "\n",
    "    calibration_pre = data1[:calibration_size]\n",
    "    main_pre = data1[calibration_size:n1]\n",
    "    main_post = data2\n",
    "\n",
    "    x_main = np.concatenate([main_pre, main_post], axis=0)\n",
    "    x_calibration_pre = calibration_pre\n",
    "\n",
    "    x_main = x_main.reshape(length, -1).astype(np.float32) / 255.0\n",
    "    x_calibration_pre = (\n",
    "        x_calibration_pre.reshape(calibration_size, -1).astype(np.float32) / 255.0\n",
    "    )\n",
    "\n",
    "    return x_main, x_calibration_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_left_scores_with_left_calibration(\n",
    "    probabilities, predicted_digits, probabilities_cal_pre, predicted_cal_pre, length\n",
    "):\n",
    "    left_scores = np.zeros((length, length))\n",
    "    left_scores_cal = np.zeros((length, len(predicted_cal_pre)))\n",
    "\n",
    "    seen_digits = {}\n",
    "\n",
    "    for i, (predicted, _) in enumerate(predicted_cal_pre):\n",
    "        if predicted in seen_digits:\n",
    "            seen_digits[predicted] += 1\n",
    "        else:\n",
    "            seen_digits[predicted] = 1\n",
    "\n",
    "    for t, (predicted, _) in enumerate(predicted_digits):\n",
    "        if predicted in seen_digits:\n",
    "            seen_digits[predicted] += 1\n",
    "        else:\n",
    "            seen_digits[predicted] = 1\n",
    "        curr_digit = max(seen_digits, key=seen_digits.get)\n",
    "\n",
    "        left_scores[t, : t + 1] = probabilities[: t + 1, curr_digit].cpu() / (\n",
    "            1 - probabilities[: t + 1, curr_digit].cpu()\n",
    "        )\n",
    "\n",
    "        left_scores_cal[t, :] = probabilities_cal_pre[:, curr_digit].cpu() / (\n",
    "            1 - probabilities_cal_pre[:, curr_digit].cpu()\n",
    "        )\n",
    "\n",
    "    return left_scores, left_scores_cal\n",
    "\n",
    "\n",
    "def compute_right_scores_without_calibration(probabilities, predicted_digits, length):\n",
    "    right_scores = np.zeros((length, length))\n",
    "\n",
    "    seen_digits = {}\n",
    "\n",
    "    for i, (predicted, _) in enumerate(reversed(predicted_digits)):\n",
    "        t = length - i - 1\n",
    "        if predicted in seen_digits:\n",
    "            seen_digits[predicted] += 1\n",
    "        else:\n",
    "            seen_digits[predicted] = 1\n",
    "        curr_digit = max(seen_digits, key=seen_digits.get)\n",
    "\n",
    "        right_scores[t, t:] = probabilities[t:, curr_digit].cpu() / (\n",
    "            1 - probabilities[t:, curr_digit].cpu()\n",
    "        )\n",
    "\n",
    "    return right_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrepancy_scores_with_left_calibration(\n",
    "    x, scores_left, scores_right, scores_left_cal\n",
    "):\n",
    "    n = len(x)\n",
    "    calibration_size_pre = scores_left_cal.shape[1]\n",
    "    discrepancy_scores = np.empty(n - 1)\n",
    "    statistics = []\n",
    "\n",
    "    for t in tqdm(range(n - 1)):\n",
    "        p = np.empty(n)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            score_r = scores_left[t, r]\n",
    "\n",
    "            main_counts = np.sum(scores_left[t, : r + 1] < score_r) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(scores_left[t, : r + 1] == score_r)\n",
    "\n",
    "            cal_counts = np.sum(scores_left_cal[t, :] < score_r) + np.random.uniform(\n",
    "                0, 1\n",
    "            ) * np.sum(scores_left_cal[t, :] == score_r)\n",
    "\n",
    "            p[r] = (main_counts + cal_counts) / (r + 1 + calibration_size_pre)\n",
    "\n",
    "        for r in range(n - 1, t, -1):\n",
    "            p[r] = (\n",
    "                np.count_nonzero(scores_right[t, r:] > scores_right[t, r])\n",
    "                + np.random.uniform(0, 1)\n",
    "                * np.count_nonzero(scores_right[t, r:] == scores_right[t, r])\n",
    "            ) / (n - r)\n",
    "\n",
    "        statistics.append(\n",
    "            (ks_1samp(p[: t + 1], uniform.cdf), ks_1samp(p[t + 1 :], uniform.cdf))\n",
    "        )\n",
    "        discrepancy_scores[t] = statistics[-1][0].statistic * np.sqrt(\n",
    "            t + 1\n",
    "        ) + statistics[-1][1].statistic * np.sqrt(n - t - 1)\n",
    "\n",
    "    return discrepancy_scores, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "changepoint = 400\n",
    "calibration_size = 100\n",
    "digit1 = 3\n",
    "digit2 = 7\n",
    "\n",
    "x_main, x_cal_pre = generate_left_calibration_mnist_dataset(\n",
    "    length, changepoint, calibration_size, digit1, digit2\n",
    ")\n",
    "\n",
    "predicted_digits = [predict_digit(model, x_main[i]) for i in tqdm(range(length))]\n",
    "probabilities = torch.vstack([prob for _, prob in predicted_digits])\n",
    "\n",
    "predicted_cal_pre = [\n",
    "    predict_digit(model, x_cal_pre[i]) for i in tqdm(range(calibration_size))\n",
    "]\n",
    "probabilities_cal_pre = torch.vstack([prob for _, prob in predicted_cal_pre])\n",
    "\n",
    "left_scores, left_scores_cal = compute_left_scores_with_left_calibration(\n",
    "    probabilities, predicted_digits, probabilities_cal_pre, predicted_cal_pre, length\n",
    ")\n",
    "\n",
    "right_scores = compute_right_scores_without_calibration(\n",
    "    probabilities, predicted_digits, length\n",
    ")\n",
    "\n",
    "discrepancy_scores_left_cal, statistics_left_cal = (\n",
    "    get_discrepancy_scores_with_left_calibration(\n",
    "        x_main, left_scores, right_scores, left_scores_cal\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ca4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_left = np.array([s[0].pvalue for s in statistics_left_cal])\n",
    "p_values_right = np.array([s[1].pvalue for s in statistics_left_cal])\n",
    "\n",
    "min_method = chi2.cdf(\n",
    "    np.minimum(2 * p_values_left, 2 * p_values_right, np.ones_like(p_values_left)), 4\n",
    ")\n",
    "threshold = 0.05\n",
    "\n",
    "plt.plot(np.arange(1, length), min_method)\n",
    "plt.axhline(\n",
    "    threshold, color=\"green\", linestyle=\":\", label=\"Threshold ($\\\\alpha = 0.05$)\"\n",
    ")\n",
    "plt.axvline(\n",
    "    changepoint, color=\"red\", linestyle=\"--\", label=\"Changepoint ($\\\\xi = 400$)\"\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\"p-values for MNIST digit change (left-side calibration)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mnist-pvalues-left-calibrated.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ef3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_set = np.argwhere(min_method > threshold).flatten()\n",
    "confidence_interval = (\n",
    "    (confidence_set[0], confidence_set[-1]) if len(confidence_set) > 0 else None\n",
    ")\n",
    "\n",
    "print(f\"True changepoint: {changepoint}\")\n",
    "print(f\"Confidence interval: {confidence_interval}\")\n",
    "print(f\"Maximum p-value at t={np.argmax(min_method)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f34d8",
   "metadata": {},
   "source": [
    "## SST-2 simulation\n",
    "\n",
    "CONCH algorithm applied to a text dataset with positive movie reviews before the changepoint and negative movie reviews after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from scipy.stats import ks_2samp, ks_1samp, uniform\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
    "plt.style.use(\"math.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
    "plt.style.use(\"math.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6235ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_sentiment_model(device=\"cpu\"):\n",
    "    model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cdd532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentiment_dataset(length, changepoint, dataset_name=\"sst2\"):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    train_data = dataset[\"train\"]\n",
    "    positive_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 1]\n",
    "    negative_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 0]\n",
    "\n",
    "    random.shuffle(positive_texts)\n",
    "    random.shuffle(negative_texts)\n",
    "\n",
    "    n1 = changepoint + 1\n",
    "    n2 = length - n1\n",
    "\n",
    "    if n1 > len(positive_texts) or n2 > len(negative_texts):\n",
    "        raise ValueError(\"Insufficient texts for the specified length and changepoint.\")\n",
    "\n",
    "    texts_before = positive_texts[:n1]\n",
    "    texts_after = negative_texts[:n2]\n",
    "\n",
    "    texts = texts_before + texts_after\n",
    "    true_labels = [1] * n1 + [0] * n2\n",
    "\n",
    "    return texts, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb909d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, tokenizer, text, device=\"cpu\"):\n",
    "    inputs = tokenizer(\n",
    "        text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).cpu()\n",
    "        predicted = probs.argmax(dim=1).item()\n",
    "\n",
    "    return (predicted, probs.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4033ccf",
   "metadata": {},
   "source": [
    "### Create dataset and see examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe62943",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "changepoint = 400\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, tokenizer = get_pretrained_sentiment_model(device)\n",
    "\n",
    "print(\"Generating sentiment dataset...\")\n",
    "texts, true_labels = generate_sentiment_dataset(length, changepoint)\n",
    "\n",
    "print(\"Getting predictions...\")\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "for i, text in enumerate(tqdm(texts)):\n",
    "    pred, prob = predict_sentiment(model, tokenizer, text, device)\n",
    "    predictions.append(pred)\n",
    "    probabilities.append(prob)\n",
    "\n",
    "probabilities = torch.stack(\n",
    "    probabilities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e855e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExamples before changepoint (positive):\")\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(0, changepoint)\n",
    "    print(f'Text {i+1}: \"{texts[idx]}\"')\n",
    "    print(\n",
    "        f\"True label: Positive, Predicted: {'Positive' if predictions[idx] == 1 else 'Negative'}\"\n",
    "    )\n",
    "    print(f\"Confidence: {probabilities[idx][predictions[idx]]:.4f}\\n\")\n",
    "\n",
    "print(\"\\nExamples after changepoint (negative):\")\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(changepoint + 1, length)\n",
    "    print(f'Text {i+1}: \"{texts[idx]}\"')\n",
    "    print(\n",
    "        f\"True label: Negative, Predicted: {'Positive' if predictions[idx] == 1 else 'Negative'}\"\n",
    "    )\n",
    "    print(f\"Confidence: {probabilities[idx][predictions[idx]]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116245de",
   "metadata": {},
   "source": [
    "### Full sentiment change (100% positive to 100% negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ba784",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_score = np.zeros((length, length))\n",
    "seen_sentiments = {0: 0, 1: 0}\n",
    "\n",
    "for t in range(length):\n",
    "    seen_sentiments[predictions[t]] += 1\n",
    "    curr_sentiment = max(seen_sentiments, key=seen_sentiments.get)\n",
    "\n",
    "    for r in range(t + 1):\n",
    "        left_score[t, r] = probabilities[r, curr_sentiment] / (\n",
    "            1 - probabilities[r, curr_sentiment]\n",
    "        )\n",
    "\n",
    "right_score = np.zeros((length, length))\n",
    "seen_sentiments = {0: 0, 1: 0}\n",
    "\n",
    "for i in range(length - 1, -1, -1):\n",
    "    t = length - i - 1\n",
    "    seen_sentiments[predictions[i]] += 1\n",
    "    curr_sentiment = max(seen_sentiments, key=seen_sentiments.get)\n",
    "\n",
    "    right_score[t, t:] = probabilities[t:, curr_sentiment] / (\n",
    "        1 - probabilities[t:, curr_sentiment]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrepancy_scores(scores_left, scores_right, length):\n",
    "    discrepancy_scores = np.empty(length - 1)\n",
    "    statistics = []\n",
    "\n",
    "    for t in tqdm(range(length - 1)):\n",
    "        p = np.empty(length)\n",
    "\n",
    "        for r in range(t + 1):\n",
    "            p[r] = (\n",
    "                np.count_nonzero(scores_left[t, : r + 1] > scores_left[t, r])\n",
    "                + np.random.uniform(0, 1)\n",
    "                * np.count_nonzero(scores_left[t, : r + 1] == scores_left[t, r])\n",
    "            ) / (r + 1)\n",
    "\n",
    "        for r in range(length - 1, t, -1):\n",
    "            p[r] = (\n",
    "                np.count_nonzero(scores_right[t, r:] > scores_right[t, r])\n",
    "                + np.random.uniform(0, 1)\n",
    "                * np.count_nonzero(scores_right[t, r:] == scores_right[t, r])\n",
    "            ) / (length - r)\n",
    "\n",
    "        statistics.append(\n",
    "            (ks_1samp(p[: t + 1], uniform.cdf), ks_1samp(p[t + 1 :], uniform.cdf))\n",
    "        )\n",
    "        discrepancy_scores[t] = statistics[-1][0].statistic * np.sqrt(\n",
    "            t + 1\n",
    "        ) + statistics[-1][1].statistic * np.sqrt(length - t - 1)\n",
    "\n",
    "    return discrepancy_scores, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrepancy_scores, statistics = get_discrepancy_scores(left_score, right_score, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f70edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "p_values_left = np.array([s[0].pvalue for s in statistics])\n",
    "p_values_right = np.array([s[1].pvalue for s in statistics])\n",
    "\n",
    "min_method = chi2.cdf(\n",
    "    np.minimum(2 * p_values_left, 2 * p_values_right, np.ones_like(p_values_left)), 4\n",
    ")\n",
    "threshold = 0.05\n",
    "\n",
    "plt.plot(np.arange(1, length), min_method)\n",
    "plt.axvline(\n",
    "    changepoint,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Changepoint ($\\\\xi = {changepoint}$)\",\n",
    ")\n",
    "plt.axhline(\n",
    "    threshold,\n",
    "    color=\"green\",\n",
    "    linestyle=\":\",\n",
    "    label=f\"Threshold ($\\\\alpha = {threshold}$)\",\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\"p-values for SST-2 sentiment change\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/sentiment-pvalues.pdf\")\n",
    "plt.show()\n",
    "\n",
    "confidence_set = np.argwhere(min_method > threshold).flatten()\n",
    "confidence_interval = (\n",
    "    (confidence_set[0], confidence_set[-1]) if len(confidence_set) > 0 else None\n",
    ")\n",
    "\n",
    "print(f\"True changepoint: {changepoint}\")\n",
    "print(f\"Confidence interval: {confidence_interval}\")\n",
    "print(f\"Maximum p-value at t={np.argmax(min_method)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dec9e5",
   "metadata": {},
   "source": [
    "### Mixed sentiment change (60% positive to 60% negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mixed_sentiment_dataset(length, changepoint, dataset_name=\"sst2\"):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    train_data = dataset[\"train\"]\n",
    "    positive_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 1]\n",
    "    negative_texts = [item[\"sentence\"] for item in train_data if item[\"label\"] == 0]\n",
    "\n",
    "    random.shuffle(positive_texts)\n",
    "    random.shuffle(negative_texts)\n",
    "\n",
    "    n_pre = changepoint + 1\n",
    "    n_post = length - n_pre\n",
    "\n",
    "    n_pos_pre = int(n_pre * 0.6)\n",
    "    n_neg_pre = n_pre - n_pos_pre\n",
    "\n",
    "    n_pos_post = int(n_post * 0.4)\n",
    "    n_neg_post = n_post - n_pos_post\n",
    "\n",
    "    if n_pos_pre + n_pos_post > len(positive_texts) or n_neg_pre + n_neg_post > len(\n",
    "        negative_texts\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Insufficient texts for the specified distribution and length.\"\n",
    "        )\n",
    "\n",
    "    pre_pos_texts = positive_texts[:n_pos_pre]\n",
    "    pre_neg_texts = negative_texts[:n_neg_pre]\n",
    "    pre_texts = pre_pos_texts + pre_neg_texts\n",
    "    pre_labels = [1] * n_pos_pre + [0] * n_neg_pre\n",
    "\n",
    "    pre_combined = list(zip(pre_texts, pre_labels))\n",
    "    random.shuffle(pre_combined)\n",
    "    pre_texts, pre_labels = zip(*pre_combined)\n",
    "\n",
    "    post_pos_texts = positive_texts[n_pos_pre : n_pos_pre + n_pos_post]\n",
    "    post_neg_texts = negative_texts[n_neg_pre : n_neg_pre + n_neg_post]\n",
    "    post_texts = post_pos_texts + post_neg_texts\n",
    "    post_labels = [1] * n_pos_post + [0] * n_neg_post\n",
    "\n",
    "    post_combined = list(zip(post_texts, post_labels))\n",
    "    random.shuffle(post_combined)\n",
    "    post_texts, post_labels = zip(*post_combined)\n",
    "\n",
    "    texts = list(pre_texts) + list(post_texts)\n",
    "    true_labels = list(pre_labels) + list(post_labels)\n",
    "\n",
    "    return texts, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "changepoint = 400\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if \"model\" not in locals() or \"tokenizer\" not in locals():\n",
    "    model, tokenizer = get_pretrained_sentiment_model(device)\n",
    "\n",
    "print(\"Generating mixed sentiment dataset (60%/40% to 40%/60%)...\")\n",
    "texts, true_labels = generate_mixed_sentiment_dataset(length, changepoint)\n",
    "\n",
    "print(\"Getting predictions...\")\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "for i, text in enumerate(tqdm(texts)):\n",
    "    pred, prob = predict_sentiment(model, tokenizer, text, device)\n",
    "    predictions.append(pred)\n",
    "    probabilities.append(prob)\n",
    "\n",
    "probabilities = torch.stack(\n",
    "    probabilities\n",
    ")\n",
    "\n",
    "left_score = np.zeros((length, length))\n",
    "seen_sentiments = {0: 0, 1: 0}\n",
    "\n",
    "for t in range(length):\n",
    "    seen_sentiments[predictions[t]] += 1\n",
    "    curr_sentiment = max(seen_sentiments, key=seen_sentiments.get)\n",
    "\n",
    "    for r in range(t + 1):\n",
    "        left_score[t, r] = probabilities[r, curr_sentiment] / (\n",
    "            1 - probabilities[r, curr_sentiment]\n",
    "        )\n",
    "\n",
    "right_score = np.zeros((length, length))\n",
    "seen_sentiments = {0: 0, 1: 0}\n",
    "\n",
    "for i in range(length - 1, -1, -1):\n",
    "    t = length - i - 1\n",
    "    seen_sentiments[predictions[i]] += 1\n",
    "    curr_sentiment = max(seen_sentiments, key=seen_sentiments.get)\n",
    "\n",
    "    right_score[t, t:] = probabilities[t:, curr_sentiment] / (\n",
    "        1 - probabilities[t:, curr_sentiment]\n",
    "    )\n",
    "\n",
    "discrepancy_scores, statistics = get_discrepancy_scores(left_score, right_score, length)\n",
    "\n",
    "p_values_left = np.array([s[0].pvalue for s in statistics])\n",
    "p_values_right = np.array([s[1].pvalue for s in statistics])\n",
    "\n",
    "min_method = chi2.cdf(\n",
    "    np.minimum(2 * p_values_left, 2 * p_values_right, np.ones_like(p_values_left)), 4\n",
    ")\n",
    "threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_set = np.argwhere(min_method > threshold).flatten()\n",
    "confidence_interval = (\n",
    "    (confidence_set[0], confidence_set[-1]) if len(confidence_set) > 0 else None\n",
    ")\n",
    "\n",
    "print(f\"True changepoint: {changepoint}\")\n",
    "print(f\"Confidence interval: {confidence_interval}\")\n",
    "print(f\"Maximum p-value at t={np.argmax(min_method)+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_positives = sum(1 for i in range(changepoint + 1) if true_labels[i] == 1)\n",
    "pre_negatives = (changepoint + 1) - pre_positives\n",
    "post_positives = sum(1 for i in range(changepoint + 1, length) if true_labels[i] == 1)\n",
    "post_negatives = (length - changepoint - 1) - post_positives\n",
    "\n",
    "print(\"\\nSentiment distribution in data:\")\n",
    "print(\n",
    "    f\"Pre-change: {pre_positives/(changepoint+1)*100:.1f}% positive, {pre_negatives/(changepoint+1)*100:.1f}% negative\"\n",
    ")\n",
    "print(\n",
    "    f\"Post-change: {post_positives/(length-changepoint-1)*100:.1f}% positive, {post_negatives/(length-changepoint-1)*100:.1f}% negative\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f355bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(min_method > threshold).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90fd9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, length), min_method)\n",
    "plt.axvline(\n",
    "    changepoint,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Changepoint ($\\\\xi = {changepoint}$)\",\n",
    ")\n",
    "plt.axhline(\n",
    "    threshold,\n",
    "    color=\"green\",\n",
    "    linestyle=\":\",\n",
    "    label=f\"Threshold ($\\\\alpha = {threshold}$)\",\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\n",
    "    \"p-values for SST-2 mixed sentiment change\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/sentiment-pvalues-mixed.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34b2ed",
   "metadata": {},
   "source": [
    "## Gaussian mean change\n",
    "\n",
    "CONCH algorithm applied to a numeric dataset with a Gaussian mean change at the changepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pvalue_matrix(\n",
    "    pvalues, changepoint=None, title=None, save_path=None, log_transform=True\n",
    "):\n",
    "    if log_transform:\n",
    "        plot_data = -np.log10(np.clip(pvalues, 1e-10, 1))\n",
    "        label = \"$-\\\\log_{10}(p_t)$\"\n",
    "    else:\n",
    "        plot_data = pvalues\n",
    "        label = \"p-value\"\n",
    "\n",
    "    fig1 = plt.figure(figsize=(10, 7))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax1.grid(False)\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    im1 = ax1.imshow(plot_data, cmap=\"viridis\", aspect=\"auto\")\n",
    "\n",
    "    cbar1 = fig1.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "    cbar1.set_label(label, fontsize=18)\n",
    "    cbar1.ax.tick_params(labelsize=16)\n",
    "\n",
    "    ax1.set_xlabel(\"$r$\", fontsize=18)\n",
    "    ax1.set_ylabel(\"$t$\", fontsize=18)\n",
    "    ax1.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "    if title:\n",
    "        ax1.set_title(title, fontsize=18)\n",
    "    else:\n",
    "        ax1.set_title(\"MCP\", fontsize=18)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(10, 7))\n",
    "    ax2 = fig2.add_subplot(111)\n",
    "    ax2.grid(False)\n",
    "    ax2.invert_yaxis()\n",
    "\n",
    "    im2 = ax2.imshow(plot_data, cmap=\"viridis\", aspect=\"auto\")\n",
    "\n",
    "    cbar2 = fig2.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "    cbar2.set_label(label, fontsize=18)\n",
    "    cbar2.ax.tick_params(labelsize=16)\n",
    "\n",
    "    t_indices, r_indices = np.indices(pvalues.shape)\n",
    "\n",
    "    condition1 = (t_indices <= 400) & (r_indices <= t_indices)\n",
    "    condition2 = (t_indices >= 400) & (r_indices > t_indices)\n",
    "    valid_mask = condition1 | condition2\n",
    "\n",
    "    validity_overlay = np.zeros((*pvalues.shape, 4))  # RGBA\n",
    "\n",
    "    validity_overlay[valid_mask] = [0, 1, 0, 0.3]\n",
    "\n",
    "    validity_overlay[~valid_mask] = [1, 0, 0, 0.3]\n",
    "\n",
    "    if pvalues.shape[0] > 400:\n",
    "        validity_overlay[398:403, :] = [\n",
    "            1,\n",
    "            1,\n",
    "            0,\n",
    "            0.7,\n",
    "        ]\n",
    "\n",
    "    ax2.imshow(validity_overlay, aspect=\"auto\")\n",
    "\n",
    "    ax2.set_xlabel(\"$r$\", fontsize=18)\n",
    "    ax2.set_ylabel(\"$t$\", fontsize=18)\n",
    "    ax2.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "    ax2.set_title(\"Validity of conformal p-values\", fontsize=18)\n",
    "\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=\"green\", alpha=0.5, label=\"Valid p-values\"),\n",
    "        Patch(facecolor=\"red\", alpha=0.5, label=\"Invalid p-values\"),\n",
    "        Patch(facecolor=\"yellow\", alpha=0.7, label=\"All valid p-values ($t=400$)\"),\n",
    "    ]\n",
    "\n",
    "    ax2.legend(handles=legend_elements, fontsize=18)\n",
    "\n",
    "    fig1.tight_layout()\n",
    "    fig2.tight_layout()\n",
    "    fig1.savefig(\"images/mcp.pdf\")\n",
    "    fig2.savefig(\"images/mcp-validity.pdf\")\n",
    "    \n",
    "    return fig1, fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd63d88",
   "metadata": {},
   "source": [
    "### Oracle (LR) score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(length, changepoint, signal_strength):\n",
    "    x = np.random.normal(-signal_strength, 1, length)\n",
    "    x[changepoint + 1 :] += 2 * signal_strength\n",
    "    return x\n",
    "\n",
    "\n",
    "def oracle_score(z, delta):\n",
    "    return np.exp(-((z - delta) ** 2) / 2) / np.exp(-((z + delta) ** 2) / 2)\n",
    "\n",
    "\n",
    "plot_mcp = False\n",
    "\n",
    "def get_discrepancy_scores(x, scores_left, scores_right):\n",
    "    discrepancy_scores = np.empty(len(x) - 1)\n",
    "    statistics = []\n",
    "    if plot_mcp:\n",
    "        all_pvalues = np.empty((len(x) - 1, len(x)))\n",
    "    for t in range(len(x) - 1):\n",
    "        p = np.empty(len(x))\n",
    "        for r in range(t + 1):\n",
    "            p[r] = (\n",
    "                np.count_nonzero(scores_left[: r + 1] > scores_left[r])\n",
    "                + np.random.uniform(0, 1)\n",
    "                * np.count_nonzero(scores_left[: r + 1] == scores_left[r])\n",
    "            ) / (r + 1)\n",
    "        for r in range(len(x) - 1, t, -1):\n",
    "            p[r] = (\n",
    "                np.count_nonzero(scores_right[r:] < scores_right[r])\n",
    "                + np.random.uniform(0, 1)\n",
    "                * np.count_nonzero(scores_right[r:] == scores_right[r])\n",
    "            ) / (len(x) - r)\n",
    "        statistics.append(\n",
    "            (\n",
    "                ks_1samp(p[: t + 1], uniform.cdf, method=\"exact\"),\n",
    "                ks_1samp(p[t + 1 :], uniform.cdf, method=\"exact\"),\n",
    "            )\n",
    "        )\n",
    "        discrepancy_scores[t] = statistics[-1][0].statistic * np.sqrt(\n",
    "            t + 1\n",
    "        ) + statistics[-1][1].statistic * np.sqrt(len(x) - t)\n",
    "\n",
    "        if plot_mcp:\n",
    "            all_pvalues[t, :] = p\n",
    "    \n",
    "    if plot_mcp:\n",
    "        plot_pvalue_matrix(all_pvalues, changepoint, \"Matrix of conformal p-values (MCP)\", \"images/mcp.pdf\")\n",
    "\n",
    "    return discrepancy_scores, statistics\n",
    "\n",
    "\n",
    "def get_log_likelihood(x, delta):\n",
    "    log_likelihood = np.empty(len(x) - 1)\n",
    "    for t in range(len(x) - 1):\n",
    "        log_likelihood[t] = (\n",
    "            -np.sum((x[: t + 1] + delta) ** 2) / 2\n",
    "            - np.sum((x[t + 1 :] - delta) ** 2) / 2\n",
    "            - len(x) / 2 * np.log(2 * np.pi)\n",
    "        )\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 1\n",
    "length = 1000\n",
    "changepoint = 400\n",
    "signal_strength = 1\n",
    "x = get_dataset(length, changepoint, signal_strength)\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffcfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_left = oracle_score(x, delta)\n",
    "scores_right = -1 / scores_left\n",
    "discrepancy_scores, statistics = get_discrepancy_scores(x, scores_left, scores_right)\n",
    "\n",
    "pvalues_left = np.array([s[0].pvalue for s in statistics])\n",
    "pvalues_right = np.array([s[1].pvalue for s in statistics])\n",
    "min_method = chi2.cdf(\n",
    "    np.minimum(2 * pvalues_left, 2 * pvalues_right, np.ones_like(pvalues_left)), 4\n",
    ")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, length), min_method)\n",
    "plt.axvline(\n",
    "    changepoint, color=\"red\", linestyle=\"--\", label=f\"Changepoint ($\\\\xi = {changepoint}$)\"\n",
    ")\n",
    "plt.axhline(\n",
    "    0.05, color=\"green\", linestyle=\":\", label=f\"Threshold ($\\\\alpha = 0.05$)\"\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\"p-values for Gaussian mean change (oracle score)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/oracle.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8aded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = np.argwhere(min_method > 0.05).flatten()\n",
    "confidence_interval = (ci[0], ci[-1]) if len(ci) > 0 else None\n",
    "print(f\"True changepoint: {changepoint}\")\n",
    "print(f\"Confidence interval: {confidence_interval}\")\n",
    "print(f\"Maximum p-value at t={np.argmax(min_method)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04b77c",
   "metadata": {},
   "source": [
    "### Learned score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_score(x):\n",
    "    from scipy.stats import norm, gaussian_kde, chi2, uniform, ks_1samp\n",
    "\n",
    "    length = len(x)\n",
    "    all_discrepancy_scores = []\n",
    "    all_statistics = []\n",
    "\n",
    "    def compute_kde(data):\n",
    "        data = np.asarray(data).reshape(-1)\n",
    "        if len(data) <= 1:\n",
    "            mean = data[0] if len(data) == 1 else 0\n",
    "            return lambda x: norm.pdf(x, loc=mean, scale=0.1)\n",
    "        return gaussian_kde(data)\n",
    "\n",
    "    for t in tqdm(range(length - 1)):\n",
    "        kde_left = compute_kde(x[: t + 1])\n",
    "        kde_right = compute_kde(x[t + 1 :])\n",
    "\n",
    "        scores_left = np.empty(length)\n",
    "        for i in range(length):\n",
    "            p_left = kde_left(x[i])\n",
    "            p_right = kde_right(x[i])\n",
    "            scores_left[i] = p_right / (p_left + 1e-10)\n",
    "\n",
    "        scores_right = -1 / (scores_left + 1e-10)\n",
    "\n",
    "        disc_scores, stats = get_discrepancy_scores(x, scores_left, scores_right)\n",
    "        all_discrepancy_scores.append(disc_scores[t])\n",
    "        all_statistics.append(stats[t])\n",
    "\n",
    "    all_discrepancy_scores = np.array(all_discrepancy_scores)\n",
    "\n",
    "    pvalues_left = np.array([s[0].pvalue for s in all_statistics])\n",
    "    pvalues_right = np.array([s[1].pvalue for s in all_statistics])\n",
    "    bonferroni_method = np.minimum(\n",
    "        np.minimum(2 * pvalues_left, 2 * pvalues_right), np.ones(len(pvalues_left))\n",
    "    )\n",
    "\n",
    "    return all_discrepancy_scores, bonferroni_method\n",
    "\n",
    "discrepancy_scores, min_method = kde_score(x)\n",
    "plt.plot(np.arange(1, length), min_method)\n",
    "plt.axvline(\n",
    "    changepoint, color=\"red\", linestyle=\"--\", label=f\"Changepoint ($\\\\xi = {changepoint}$)\"\n",
    ")\n",
    "plt.axhline(\n",
    "    0.05, color=\"green\", linestyle=\":\", label=f\"Threshold ($\\\\alpha = 0.05$)\"\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\"p-values for Gaussian mean change (learned score)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/learned.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_set = np.argwhere(min_method > 0.05).flatten()\n",
    "confidence_interval = (\n",
    "    (confidence_set[0], confidence_set[-1]) if len(confidence_set) > 0 else None\n",
    ")\n",
    "print(f\"True changepoint: {changepoint}\")\n",
    "print(f\"Confidence interval: {confidence_interval}\")\n",
    "print(f\"Maximum p-value at t={np.argmax(min_method)+1}\")\n",
    "\n",
    "plt.plot(np.arange(1, length), min_method)\n",
    "plt.axvline(\n",
    "    changepoint,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Changepoint ($\\\\xi = {changepoint}$)\",\n",
    ")\n",
    "plt.axhline(0.05, color=\"green\", linestyle=\":\", label=f\"Threshold ($\\\\alpha = 0.05$)\")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"p-value ($p_t$)\")\n",
    "plt.title(\"p-values for Gaussian mean change (learned score)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/learned.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
